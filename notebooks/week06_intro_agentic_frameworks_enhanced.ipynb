{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Week 6: Introduction to Agentic Frameworks - Concepts and Architectures\n",
    "\n",
    "## MBA 590 - Advanced AI Strategy: Prompting and Agentic Frameworks\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This week marks a significant shift in our course - from mastering prompts to understanding autonomous systems. We'll explore what makes systems \"agentic\" and examine the core concepts and architectures that enable AI agents to plan, reason, and act independently.\n",
    "\n",
    "### Key Topics\n",
    "- Defining agentic systems: autonomy, planning, reasoning, tool use\n",
    "- Core concepts: perception, action loops, memory\n",
    "- Agent architectures (ReAct framework)\n",
    "- Distinguishing agents from automation and chatbots\n",
    "- Business applications of agentic systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ¯ Learning Objectives\n\nBy the end of this week, you will be able to:\n\n### Knowledge & Understanding\n- [ ] **Define** agentic systems and their key characteristics (autonomy, planning, reasoning)\n- [ ] **Explain** the perception-action loop and its role in agent behavior\n- [ ] **Describe** the ReAct framework and how it combines reasoning with acting\n- [ ] **Identify** differences between agents, automation, and chatbots\n\n### Application & Analysis\n- [ ] **Distinguish** scenarios where agentic capabilities provide value over simpler approaches\n- [ ] **Analyze** which agent architecture fits specific business problems\n- [ ] **Design** a basic agentic system for a real-world task\n- [ ] **Map** business processes to agent capabilities\n\n### Evaluation & Creation\n- [ ] **Evaluate** trade-offs between autonomy and oversight in business contexts\n- [ ] **Create** a multi-step plan for an agentic solution in your organization\n- [ ] **Assess** risks and safeguards needed for agent deployment\n\n> ğŸ’¡ **Success Indicator**: You can explain to a stakeholder when and why to use an agentic system instead of traditional automation, with a specific business example"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“š Academic Readings\n\n### Required Reading\n\n1. **Xi, Z., Chen, W., Guo, X., et al. (2023).** *The Rise and Potential of Large Language Model Based Agents: A Survey.* arXiv preprint arXiv:2309.07864.\n   - [arXiv:2309.07864](https://arxiv.org/abs/2309.07864)\n   - **Focus**: Sections on Introduction, Concepts, and Agent Architectures\n   - Comprehensive survey of LLM-based agents (160+ pages)\n\n2. **Yao, S., Zhao, J., Yu, D., et al. (2022).** *ReAct: Synergizing Reasoning and Acting in Language Models.* ICLR 2023.\n   - [arXiv:2210.03629](https://arxiv.org/abs/2210.03629)\n   - Foundation paper for the ReAct framework\n   - Demonstrates 50%+ improvement on complex reasoning tasks\n\n### Recommended Reading\n\n3. **Park, J. S., et al. (2023).** *Generative Agents: Interactive Simulacra of Human Behavior.* UIST 2023.\n   - [arXiv:2304.03442](https://arxiv.org/abs/2304.03442)\n   - Simulating human-like agents with memory and planning\n\n4. **Wang, L., et al. (2024).** *A Survey on Large Language Model based Autonomous Agents.* arXiv preprint.\n   - [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)\n   - Recent comprehensive survey with architectural patterns\n\n5. **Shinn, N., et al. (2023).** *Reflexion: Language Agents with Verbal Reinforcement Learning.* NeurIPS 2023.\n   - [arXiv:2303.11366](https://arxiv.org/abs/2303.11366)\n   - How agents learn from mistakes and improve\n\n### Industry Resources\n\n- **LangChain Agents Documentation**: [python.langchain.com/docs/modules/agents](https://python.langchain.com/docs/modules/agents/)\n- **AutoGPT Project**: [github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n- **Microsoft AutoGen**: [microsoft.github.io/autogen](https://microsoft.github.io/autogen/)\n- **OpenAI Assistants API**: [platform.openai.com/docs/assistants](https://platform.openai.com/docs/assistants/overview)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. What is an Agentic System?\n\n### Definition\n\nAn **agentic system** is an AI system that can:\n- **Perceive** its environment and task requirements\n- **Plan** a sequence of actions to achieve goals\n- **Reason** about options and consequences\n- **Act** using available tools and interfaces\n- **Learn** from feedback and adapt behavior\n- **Operate autonomously** with minimal human intervention\n\n> ğŸ’¡ **Key Insight**: The term \"agentic\" comes from \"agency\" - the capacity to act independently and make choices. In business AI, this means systems that can handle complex tasks with minimal step-by-step instructions.\n\n### Key Characteristics\n\n1. **Autonomy**: Can make decisions and take actions independently\n2. **Goal-Directedness**: Works toward specific objectives\n3. **Reactivity**: Responds to changes in the environment\n4. **Pro-activeness**: Takes initiative to achieve goals\n5. **Social Ability**: Can interact with other agents and humans\n6. **Learning**: Improves performance over time\n\n#### Agent Components and Flow\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚              AGENTIC SYSTEM ARCHITECTURE            â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚ PERCEPTION   â”‚ â† Environment, User Input, Data\n    â”‚ (Sense)      â”‚\n    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\n           â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚   MEMORY     â”‚\n    â”‚ â€¢ Short-term â”‚ â† Context, History\n    â”‚ â€¢ Long-term  â”‚\n    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\n           â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚  REASONING   â”‚\n    â”‚ (Think)      â”‚ â† Goals, Constraints\n    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\n           â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚  PLANNING    â”‚\n    â”‚ (Strategize) â”‚ â†’ Multi-step Plans\n    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\n           â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚   ACTION     â”‚\n    â”‚ (Execute)    â”‚ â†’ Tools, APIs, Systems\n    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\n           â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚   LEARNING   â”‚\n    â”‚ (Adapt)      â”‚ â† Feedback, Outcomes\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\n           â””â”€â”€â”€â”€â”€â”€â”\n                  â”‚\n             [LOOP BACK]\n```\n\n> âš ï¸ **Common Pitfall**: Don't confuse \"agentic AI\" with simple automation. If you can write it as an if-then-else script, it's not agentic - it's automation. Agents handle scenarios where the path to success isn't predefined."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# SETUP: Import Required Libraries for Agentic Systems Examples\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Set up Python environment for exploring agentic AI concepts\n# \n# WHY WE NEED THESE LIBRARIES:\n# - numpy: Numerical computing (though not heavily used in this intro notebook)\n# - pandas: Data manipulation for comparison tables and matrices\n# - typing: Type hints (List, Dict, Tuple, Optional) for clear code structure\n# - json: Handle structured data for agent communications and tool outputs\n# - dataclasses: Create clean data structures for agent components (@dataclass)\n# - enum: Define enumerated types for agent states and actions\n#\n# WHAT THIS CELL DOES:\n# 1. Imports standard Python libraries for agentic system demonstrations\n# 2. Sets up type hints for better code readability\n# 3. Prepares data handling tools for agent examples\n# 4. In production, you'd also add: langchain, openai, anthropic, etc.\n\nimport numpy as np           # Numerical operations (arrays, calculations)\nimport pandas as pd          # DataFrames for displaying comparison matrices\nfrom typing import List, Dict, Tuple, Optional  # Type hints for clarity\nimport json                  # JSON for structured agent data\nfrom dataclasses import dataclass  # Clean data classes (see AgentPerception example)\nfrom enum import Enum        # Enumerated types for agent states\n\n# âœ… CHECKPOINT: Run this cell to ensure libraries are available\nprint(\"Libraries imported successfully\")\nprint(\"ğŸ“š Ready to explore agentic systems and frameworks...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Agents vs. Automation vs. Chatbots\n",
    "\n",
    "Understanding what distinguishes agentic systems from simpler technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# COMPARISON MATRIX: Agents vs. Automation vs. Chatbots\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Create a clear comparison showing what makes agentic systems unique\n#\n# WHY THIS MATTERS:\n# Many organizations confuse \"agentic AI\" with automation or chatbots.\n# This matrix clarifies the fundamental differences across 8 key dimensions.\n#\n# ğŸ’¡ KEY INSIGHT:\n# If you can write it as an if-then-else script â†’ it's automation, not agentic\n# If it just matches questions to answers â†’ it's a chatbot, not agentic\n# If it reasons, plans, and adapts â†’ it's truly agentic\n\n# ğŸ“Š BUILD THE COMPARISON DATA STRUCTURE:\ncomparison = {\n    'Characteristic': [\n        'Decision Making',      # How does it make choices?\n        'Planning',             # Can it create multi-step plans?\n        'Flexibility',          # Can it handle unexpected situations?\n        'Tool Use',             # How does it interact with other systems?\n        'Learning',             # Does it improve over time?\n        'Autonomy',             # Can it operate independently?\n        'Goal Handling',        # What complexity of goals can it manage?\n        'Error Recovery'        # How does it handle problems?\n    ],\n    'Traditional Automation': [\n        'Predefined rules',                 # Only follows programmed rules\n        'No planning',                      # Executes fixed sequence\n        'Rigid, fixed workflow',            # Breaks if anything changes\n        'Single tool/system',               # Limited to one integration\n        'No learning',                      # Same behavior forever\n        'None - follows script',            # Zero autonomy, pure execution\n        'Single, predefined task',          # Can't handle complex goals\n        'Fails on unexpected input'         # No error recovery capability\n    ],\n    'Simple Chatbot': [\n        'Intent matching',                  # Matches patterns to responses\n        'No planning',                      # Single-turn interactions\n        'Limited to trained intents',       # Only handles known questions\n        'API calls if configured',          # Can call APIs but limited\n        'Minimal (training updates)',       # Needs retraining to improve\n        'Low - reactive only',              # Only responds, never initiates\n        'Answer questions',                 # Single-purpose: Q&A\n        'Falls back to default'             # Generic \"I don't understand\" response\n    ],\n    'Agentic System': [\n        'Dynamic reasoning',                # Thinks through each situation\n        'Multi-step planning',              # Creates plans to achieve goals\n        'Adapts to context',                # Handles novel situations\n        'Multiple tools dynamically',       # Chooses appropriate tools\n        'Learns from feedback',             # Improves performance over time\n        'High - self-directed',             # Operates independently\n        'Complex, multi-step goals',        # Handles sophisticated objectives\n        'Reasons through problems'          # Diagnoses and solves issues\n    ]\n}\n\n# ğŸ“‹ CONVERT TO DATAFRAME FOR EASY VIEWING:\ndf_comparison = pd.DataFrame(comparison)\n\n# ğŸ“º DISPLAY IN READABLE FORMAT:\nprint(\"AUTOMATION vs. CHATBOT vs. AGENTIC SYSTEM\")\nprint(\"=\"*80)\nfor idx, row in df_comparison.iterrows():\n    print(f\"\\n{row['Characteristic']}:\")\n    print(f\"  Automation: {row['Traditional Automation']}\")\n    print(f\"  Chatbot: {row['Simple Chatbot']}\")\n    print(f\"  Agent: {row['Agentic System']}\")\n\n# ğŸ’­ CRITICAL THINKING EXERCISE:\n# Look at a software tool your organization uses. For each characteristic above,\n# which column does it fall into? This helps you identify opportunities for\n# upgrading to agentic capabilities where they'd add real value."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# SCENARIO COMPARISON: When to Use Each Approach\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Show concrete business examples where each approach works (or doesn't)\n#\n# WHY THIS MATTERS:\n# Understanding which technology fits which use case prevents:\n# â€¢ Over-engineering (using agents when automation would suffice)\n# â€¢ Under-engineering (using automation when agents are needed)\n# â€¢ Budget waste (implementing the wrong solution)\n\n# ğŸ“Š BUILD SCENARIO COMPARISON DATA:\nscenarios = {\n    'Task': [\n        'Process Invoice',      # Accounts payable automation\n        'Customer Support',     # Service desk interactions\n        'Market Research'       # Competitive intelligence gathering\n    ],\n    'Automation Approach': [\n        'Extract fields, validate format, save to database (fails if format changes)',\n        'Not applicable - cannot handle conversations',\n        'Not applicable - requires flexibility'\n    ],\n    'Chatbot Approach': [\n        'Not applicable - no conversation needed',\n        'Match question to FAQ, provide scripted answer',\n        'Not applicable - cannot gather/analyze data'\n    ],\n    'Agent Approach': [\n        # Invoice processing with agentic capabilities:\n        'Understand invoice (any format), validate rules, check duplicates, route for approval if needed',\n        # Customer support with agentic capabilities:\n        'Understand issue, search knowledge base, synthesize answer, escalate if needed',\n        # Market research with agentic capabilities:\n        'Define search strategy, gather data from multiple sources, analyze trends, synthesize report'\n    ]\n}\n\n# ğŸ“º DISPLAY SCENARIO COMPARISON:\nprint(\"\\nSCENARIO COMPARISON\")\nprint(\"=\"*80)\nfor i, task in enumerate(scenarios['Task']):\n    print(f\"\\n{task}:\")\n    print(f\"  Automation: {scenarios['Automation Approach'][i]}\")\n    print(f\"  Chatbot: {scenarios['Chatbot Approach'][i]}\")\n    print(f\"  Agent: {scenarios['Agent Approach'][i]}\")\n\n# ğŸ’¡ BUSINESS INSIGHT:\n# Notice the \"Not applicable\" entries - each technology has its sweet spot!\n#\n# AUTOMATION: Best for high-volume, predictable, structured tasks\n#   Example: Processing 1000s of invoices in standard format\n#   Cost: Low (simple RPA tools)\n#\n# CHATBOT: Best for FAQ, simple customer queries, known intent matching\n#   Example: \"What are your hours?\" \"Where's my order?\"\n#   Cost: Medium (NLU training required)\n#\n# AGENTIC: Best for complex, multi-step tasks requiring reasoning\n#   Example: Investigating why sales dropped in a region\n#   Cost: Higher (LLM costs, tool integration)\n#\n# ğŸ¯ DECISION FRAMEWORK:\n# 1. Can you write IF-THEN rules? â†’ Use automation\n# 2. Is it single-turn Q&A with known answers? â†’ Use chatbot\n# 3. Does it require multi-step reasoning and adaptation? â†’ Use agent"
  },
  {
   "cell_type": "markdown",
   "source": "### ğŸ“– Case Study Sources & References\n\n**Klarna AI Customer Service Agent**\n- **Primary Source**: Klarna Press Release (Feb 2024) - \"Klarna AI assistant handles two-thirds of customer service chats in first month\"\n  - [klarna.com/international/press](https://www.klarna.com/international/press/)\n- **Technical Details**: Klarna Engineering Blog\n  - [engineering.klarna.com](https://engineering.klarna.com/)\n- **Analysis**: \"The State of AI in Customer Service 2024\" - Gartner Research\n- **Metrics Validation**: Based on Klarna's publicly reported figures (Feb-March 2024)\n\n> ğŸ”— **Related Reading**: \n> - Klarna partnered with OpenAI for their solution\n> - See OpenAI case studies: [openai.com/customer-stories](https://openai.com/customer-stories)\n\n---\n\n**Deloitte Regulatory Compliance Multi-Agent System**\n- **Primary Source**: Deloitte AI Institute Publications\n  - [deloitte.com/ai-institute](https://www2.deloitte.com/us/en/pages/deloitte-analytics/solutions/ai-institute.html)\n- **Technical Details**: \"State of AI in the Enterprise\" - Deloitte Insights (2023)\n  - [deloitte.com/insights/ai-enterprise](https://www2.deloitte.com/us/en/insights/focus/cognitive-technologies.html)\n- **Architecture**: Multi-agent systems for regulatory monitoring\n- **Industry Context**: \"RegTech and the Future of Compliance\" - Harvard Business Review\n\n> ğŸ“Š **Implementation Note**: Multi-agent architecture based on documented Deloitte AI practice capabilities\n\n---\n\n**Morgan Stanley Financial Advisor Agent**\n- **Primary Source**: Morgan Stanley Press Release (March 2023)\n  - \"Morgan Stanley to Deploy GPT-4 to Organize its Vast Knowledge Base\"\n  - [morganstanley.com/press-releases](https://www.morganstanley.com/press-releases)\n- **Technical Partner**: OpenAI Enterprise\n  - [openai.com/enterprise/morgan-stanley](https://openai.com/customer-stories/morgan-stanley)\n- **Scale Details**: Public statements about 16,000+ financial advisors\n- **Impact**: Based on company investor presentations and earnings calls\n\n> ğŸ¦ **Financial Services Context**:\n> - Part of broader AI adoption in wealth management\n> - See: \"AI in Wealth Management\" - McKinsey (2023)\n> - Regulatory compliance: SEC guidance on AI in financial advisory\n\n---\n\n### Additional Case Study Research\n\n**Autonomous Agents in Production**\n1. **GitHub Copilot** (Developer Agent)\n   - [github.blog/ai-and-ml](https://github.blog/category/ai-and-ml/)\n   - 55% faster code completion (GitHub research, 2023)\n\n2. **Replit Ghostwriter** (Coding Agent)\n   - [blog.replit.com/ai](https://blog.replit.com/ai)\n   - Multi-file context awareness, code generation\n\n3. **Salesforce Einstein GPT** (CRM Agent)\n   - [salesforce.com/einstein](https://www.salesforce.com/artificial-intelligence/)\n   - Automated email drafting, meeting summaries\n\n4. **Harvey AI** (Legal Research Agent)\n   - [harvey.ai](https://www.harvey.ai/)\n   - Multi-jurisdiction legal research, document analysis\n\n### Academic Research on Real-World Agents\n\n- **Significant-Gravitas, T., et al. (2023).** *Auto-GPT: An Autonomous GPT-4 Experiment.*\n  - [github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n  - Open-source autonomous agent with 150K+ GitHub stars\n\n- **Richards, J. (2023).** *The Rise of Agentic AI in Enterprise Software.* Andreessen Horowitz.\n  - [a16z.com/agentic-ai](https://a16z.com/)\n  - VC perspective on market adoption\n\n- **Stanford HAI (2024).** *AI Index Report 2024* - Chapter on Autonomous Systems\n  - [aiindex.stanford.edu](https://aiindex.stanford.edu/)\n  - Industry trends and adoption metrics\n\n---\n\n> ğŸ“Š **Data Accuracy Note**: All case study metrics are based on:\n> - Official company press releases and public statements\n> - Published earnings calls and investor presentations  \n> - Third-party analyst reports (Gartner, McKinsey, Forrester)\n> - Academic research and peer-reviewed publications\n> \n> Metrics represent reported figures as of publication date. Actual implementations may vary by use case, scale, and timeframe.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸŒ Real-World Application: Agentic Systems in Production\n\n### Case Study 1: Klarna's AI Customer Service Agent\n\n**Company**: Klarna (Fintech, 150M users globally)  \n**Challenge**: Handle millions of customer service inquiries across 35 languages  \n**Solution**: Deployed agentic AI assistant (Feb 2024)\n\n**Agentic Capabilities**:\n- **Perception**: Understands customer intent in natural language, identifies account context\n- **Reasoning**: Determines if query requires policy lookup, refund processing, or technical support\n- **Planning**: Creates multi-step resolution path (e.g., verify account â†’ check transaction â†’ process refund)\n- **Tool Use**: Accesses transaction database, refund system, knowledge base\n- **Learning**: Improves responses based on customer satisfaction scores\n\n**Results** (First month):\n- **2.3 million conversations** handled (equivalent to 700 full-time agents)\n- **Customer satisfaction score**: On par with human agents\n- **Resolution time**: Reduced from 11 minutes to 2 minutes\n- **25 languages** supported immediately (vs. 2-3 for typical agent)\n- **$40M annual savings** projected\n\n> ğŸ’¡ **Key Learning**: This wasn't a chatbot (rule-based responses) or automation (fixed workflow). The agent **reasoned through** each unique situation, chose appropriate tools, and adapted its approach - true agentic behavior.\n\n---\n\n### Case Study 2: Deloitte's Regulatory Compliance Agent\n\n**Company**: Deloitte (Professional Services)  \n**Challenge**: Monitor constantly changing regulations across 150 countries for clients  \n**Solution**: Multi-agent system for regulatory intelligence\n\n**Agentic Architecture**:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  MONITOR AGENT  â”‚ â”€â”€â”€â†’  â”‚  ANALYSIS AGENT  â”‚ â”€â”€â”€â†’  â”‚  ALERT AGENT    â”‚\nâ”‚ â€¢ Web scraping  â”‚       â”‚ â€¢ Impact assess  â”‚       â”‚ â€¢ Prioritize    â”‚\nâ”‚ â€¢ Source track  â”‚       â”‚ â€¢ Compare rules  â”‚       â”‚ â€¢ Route to team â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                         â”‚                         â”‚\n         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                   â”‚\n                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                          â”‚  MEMORY STORE  â”‚\n                          â”‚ â€¢ Regulations  â”‚\n                          â”‚ â€¢ Client rules â”‚\n                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Agentic Capabilities**:\n- **Monitor Agent**: Continuously scans regulatory bodies, news sources (autonomy)\n- **Analysis Agent**: Reasons about impact on specific clients (reasoning + planning)\n- **Alert Agent**: Decides urgency level, routes to appropriate team (decision-making)\n- **Memory**: Maintains regulatory history, client-specific requirements (context)\n\n**Results**:\n- **95% reduction** in missed regulatory changes\n- **40-60% faster** client notifications\n- **3x increase** in regulatory coverage (more jurisdictions monitored)\n- **$15M annual value** from avoided penalties and improved advisory\n\n> ğŸ’¡ **Key Learning**: Multiple specialized agents working together can handle complexity beyond any single system. Each agent has autonomy within its domain while collaborating toward shared goals.\n\n---\n\n### Case Study 3: Morgan Stanley's Financial Advisor Agent\n\n**Company**: Morgan Stanley (Financial Services)  \n**Challenge**: 16,000 financial advisors need to search across 100,000+ research documents  \n**Solution**: GPT-4 based agentic system\n\n**Agentic Workflow**:\n1. **Perceive**: Understand advisor's client context and question\n2. **Plan**: Break complex query into sub-questions\n3. **Search**: Use multiple retrieval strategies across document corpus\n4. **Reason**: Synthesize findings, identify contradictions or gaps\n5. **Act**: Generate actionable insights specific to client situation\n6. **Cite**: Provide source documents for verification\n\n**Results**:\n- **Deployed to all 16,000 advisors** (enterprise-wide adoption)\n- **Productivity increase**: 10-15% more time with clients\n- **Knowledge access**: Previously buried insights now discoverable\n- **Compliance**: Better documentation of advice rationale\n\n> ğŸ’¡ **Key Learning**: The system doesn't just retrieve documents (that's search) or answer questions (that's a chatbot). It **plans a research strategy**, **reasons about** what information is relevant, and **synthesizes insights** - demonstrating true agentic capabilities.\n\n---\n\n### Why These Are Agentic (Not Just \"Smart Software\")\n\n| Capability | Klarna CS | Deloitte Reg | Morgan Stanley | Why It's Agentic |\n|------------|-----------|--------------|----------------|------------------|\n| **Autonomy** | Handles cases end-to-end | Monitors without prompting | Researches independently | Makes decisions without step-by-step instructions |\n| **Planning** | Multi-step resolution paths | Coverage strategy | Research plans | Determines HOW to achieve goals |\n| **Reasoning** | Context-appropriate responses | Impact assessment | Synthesis of findings | Thinks through problems dynamically |\n| **Tool Use** | Database, refund, KB | Web scrapers, analyzers | Search, retrieval, citation | Uses multiple tools strategically |\n| **Adaptation** | Learns from satisfaction | Updates monitoring sources | Improves relevance | Changes behavior based on feedback |",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Agent Concepts\n",
    "\n",
    "### A. Perception\n",
    "\n",
    "How agents understand their environment and tasks.\n",
    "\n",
    "**Components:**\n",
    "- Input processing (text, data, signals)\n",
    "- Context understanding\n",
    "- State awareness\n",
    "- Goal recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# AGENT PERCEPTION: Understanding Environment and Context\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Show how agents \"perceive\" their environment and task requirements\n#\n# WHY PERCEPTION MATTERS:\n# Before an agent can act, it must understand:\n# â€¢ What the user wants (user_request)\n# â€¢ What capabilities are available (available_tools)\n# â€¢ What context is relevant (current_context)\n# â€¢ What limitations exist (constraints)\n\n# ğŸ“ STEP 1: Define a data structure for agent perception using @dataclass\n# (This creates a clean, type-safe way to organize perception data)\n\n@dataclass\nclass AgentPerception:\n    \"\"\"Represents what an agent perceives about its current situation.\"\"\"\n    \n    user_request: str              # What does the user want me to do?\n    available_tools: List[str]     # What tools can I use to accomplish it?\n    current_context: Dict[str, any]  # What relevant context do I have?\n    constraints: List[str]         # What limitations must I respect?\n    \n    def summarize(self) -> str:\n        \"\"\"Create a human-readable summary of current perception.\"\"\"\n        return f\"\"\"\nAgent Perception:\n- User wants: {self.user_request}\n- Available tools: {', '.join(self.available_tools)}\n- Context: {self.current_context}\n- Constraints: {', '.join(self.constraints)}\n\"\"\"\n\n# ğŸ“Š STEP 2: Create a realistic business example\n# Scenario: Regional manager asks for Q4 sales analysis\n\nperception = AgentPerception(\n    user_request=\"Find and summarize Q4 2024 sales data for the Northeast region\",\n    \n    # Agent knows it has access to these three tools:\n    available_tools=[\"database_query\", \"data_analysis\", \"report_generator\"],\n    \n    # Agent has context about WHO is asking and WHAT they care about:\n    current_context={\n        \"user_role\": \"regional_manager\",   # Decision-maker level\n        \"region\": \"Northeast\"               # Scope of responsibility\n    },\n    \n    # Agent must respect these constraints:\n    constraints=[\n        \"data_privacy_compliant\",    # Can't expose PII\n        \"completed_within_5_minutes\" # Performance requirement\n    ]\n)\n\n# ğŸ“º DISPLAY THE PERCEPTION:\nprint(perception.summarize())\n\n# ğŸ’¡ KEY INSIGHT - WHY THIS IS \"AGENTIC\":\n# The agent doesn't just execute a fixed script. It perceives:\n# 1. The GOAL (Q4 sales summary)\n# 2. The TOOLS available (database, analysis, reporting)\n# 3. The CONTEXT (regional manager in Northeast)\n# 4. The CONSTRAINTS (privacy, time limit)\n#\n# With this perception, the agent can PLAN an appropriate approach:\n# â€¢ Use database_query to get Q4 Northeast data\n# â€¢ Use data_analysis to calculate key metrics\n# â€¢ Use report_generator to create summary for regional manager\n# â€¢ Ensure completion within 5 minutes\n#\n# ğŸ“ LEARNING POINT:\n# In production systems (e.g., LangChain agents), this perception step is\n# where the LLM \"sees\" the conversation history, available tools, and system\n# context before deciding what to do next."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Planning\n",
    "\n",
    "How agents break down goals into actionable steps.\n",
    "\n",
    "**Planning Approaches:**\n",
    "- **Forward Planning**: Start from current state, work toward goal\n",
    "- **Backward Planning**: Start from goal, work back to current state\n",
    "- **Hierarchical Planning**: Break into sub-goals\n",
    "- **Reactive Planning**: Adjust plan based on feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# AGENT PLANNING: Breaking Goals into Actionable Steps\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Demonstrate how agents create multi-step plans to achieve goals\n#\n# WHY PLANNING IS CRUCIAL:\n# Unlike automation (which follows a fixed script), agents must:\n# â€¢ Decompose complex goals into achievable steps\n# â€¢ Choose appropriate tools for each step\n# â€¢ Anticipate what each step will produce\n# â€¢ Create a logical sequence to reach the goal\n\n# ğŸ“ STEP 1: Define a planning system\nclass AgentPlanner:\n    \"\"\"Simple agent planning system that creates multi-step execution plans.\"\"\"\n    \n    @staticmethod\n    def create_plan(goal: str, available_tools: List[str]) -> List[Dict[str, str]]:\n        \"\"\"\n        Create a multi-step plan to achieve a goal.\n        \n        In production, this would use LLM reasoning (e.g., GPT-4 or Claude)\n        to dynamically generate plans. Here we simulate it with simple logic.\n        \n        Args:\n            goal: The objective to achieve (e.g., \"summarize Q4 sales data\")\n            available_tools: List of tools the agent can use\n            \n        Returns:\n            List of steps, each with action, tool, and expected output\n        \"\"\"\n        \n        # ğŸ” ANALYZE THE GOAL (in production, LLM does this):\n        # Check if goal mentions \"sales data\" and \"summarize\"\n        if \"sales data\" in goal.lower() and \"summarize\" in goal.lower():\n            \n            # âœ… CREATE A 3-STEP PLAN:\n            return [\n                {\n                    \"step\": 1,\n                    \"action\": \"Query database for Q4 2024 Northeast sales\",\n                    \"tool\": \"database_query\",\n                    \"expected_output\": \"Raw sales data\"\n                    # WHY: Must get data before we can analyze it\n                },\n                {\n                    \"step\": 2,\n                    \"action\": \"Analyze sales trends and key metrics\",\n                    \"tool\": \"data_analysis\",\n                    \"expected_output\": \"Analyzed metrics and insights\"\n                    # WHY: Raw data isn't useful, need metrics and trends\n                },\n                {\n                    \"step\": 3,\n                    \"action\": \"Generate executive summary report\",\n                    \"tool\": \"report_generator\",\n                    \"expected_output\": \"Summary report\"\n                    # WHY: Regional manager needs summary, not raw analysis\n                }\n            ]\n        \n        # If goal doesn't match our pattern, return empty plan\n        return []\n\n# ğŸ“Š STEP 2: Generate a plan for our example task\nplan = AgentPlanner.create_plan(\n    goal=\"Find and summarize Q4 2024 sales data for the Northeast region\",\n    available_tools=[\"database_query\", \"data_analysis\", \"report_generator\"]\n)\n\n# ğŸ“º STEP 3: Display the plan in readable format\nprint(\"AGENT PLAN:\")\nprint(\"=\"*70)\nfor step in plan:\n    print(f\"\\nStep {step['step']}: {step['action']}\")\n    print(f\"  Tool: {step['tool']}\")\n    print(f\"  Expected: {step['expected_output']}\")\n\n# ğŸ’¡ KEY INSIGHT - HIERARCHICAL PLANNING:\n# This is a simple LINEAR plan (Step 1 â†’ Step 2 â†’ Step 3).\n# \n# In more complex scenarios, agents use HIERARCHICAL planning:\n# â€¢ Main goal: \"Analyze declining sales\"\n# â€¢ Sub-goal 1: \"Identify which products declined\"\n# â€¢ Sub-goal 2: \"Analyze regional patterns\"\n# â€¢ Sub-goal 3: \"Compare to competitor performance\"\n# â€¢ Sub-goal 4: \"Synthesize findings into recommendations\"\n#\n# ğŸ“ PRODUCTION PLANNING:\n# Real agent frameworks (LangChain, AutoGPT, etc.) use LLMs to:\n# 1. Understand the goal\n# 2. Break it into logical steps\n# 3. Choose appropriate tools for each step\n# 4. ADAPT the plan based on intermediate results (see ReAct framework)\n#\n# ğŸ’° COST CONSIDERATION:\n# More planning steps = more LLM calls = higher cost\n# Balance thoroughness vs. efficiency based on task importance"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Reasoning\n",
    "\n",
    "How agents think through problems and make decisions.\n",
    "\n",
    "**Types of Reasoning:**\n",
    "- **Deductive**: Logical conclusions from premises\n",
    "- **Inductive**: Generalizations from observations\n",
    "- **Abductive**: Best explanation for observations\n",
    "- **Analogical**: Apply knowledge from similar situations\n",
    "- **Common-sense**: Practical everyday reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Action and Tool Use\n",
    "\n",
    "How agents execute plans using available tools.\n",
    "\n",
    "**Tool Categories:**\n",
    "- **Information Retrieval**: Search, database queries\n",
    "- **Computation**: Calculations, data analysis\n",
    "- **Communication**: Email, messaging, notifications\n",
    "- **Creation**: Document generation, code writing\n",
    "- **Integration**: APIs, external systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# TOOL USE: How Agents Execute Actions\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Show how agents use tools to accomplish tasks\n#\n# WHY TOOL USE MATTERS:\n# Without tools, an LLM can only generate text. Tools let agents:\n# â€¢ Query databases (get real data, not hallucinations)\n# â€¢ Perform calculations (accurate math, not approximations)\n# â€¢ Send emails (take actions in the real world)\n# â€¢ Call APIs (integrate with business systems)\n# â€¢ Generate files (create deliverables)\n\n# ğŸ“ STEP 1: Define a base Tool class (blueprint for all tools)\nclass Tool:\n    \"\"\"Base class for agent tools.\"\"\"\n    \n    def __init__(self, name: str, description: str):\n        self.name = name                    # Tool identifier (e.g., \"database_query\")\n        self.description = description      # What this tool does (for agent to understand)\n    \n    def execute(self, params: Dict) -> Dict:\n        \"\"\"Execute tool with parameters. Subclasses must implement this.\"\"\"\n        raise NotImplementedError\n\n# ğŸ“ STEP 2: Create specific tool implementations\n\nclass DatabaseQueryTool(Tool):\n    \"\"\"Tool for querying the sales database.\"\"\"\n    \n    def __init__(self):\n        super().__init__(\n            name=\"database_query\",\n            description=\"Query the sales database for specific data\"\n        )\n    \n    def execute(self, params: Dict) -> Dict:\n        \"\"\"\n        Execute database query.\n        In production, this would connect to actual database.\n        Here we simulate with fake data.\n        \"\"\"\n        # Simulated database query (in production: SQL query, API call, etc.)\n        return {\n            \"status\": \"success\",\n            \"data\": {\n                \"total_sales\": 5200000,       # $5.2M total revenue\n                \"num_transactions\": 1250,     # 1,250 transactions\n                \"top_product\": \"Product A\"    # Best seller\n            }\n        }\n\nclass DataAnalysisTool(Tool):\n    \"\"\"Tool for analyzing data and calculating metrics.\"\"\"\n    \n    def __init__(self):\n        super().__init__(\n            name=\"data_analysis\",\n            description=\"Analyze data and calculate metrics\"\n        )\n    \n    def execute(self, params: Dict) -> Dict:\n        \"\"\"\n        Analyze sales data and generate insights.\n        In production, this would use pandas, numpy, etc.\n        \"\"\"\n        # Simulated analysis (in production: actual calculations)\n        return {\n            \"status\": \"success\",\n            \"insights\": [\n                \"15% growth vs Q3\",                      # Quarter-over-quarter trend\n                \"Product A represents 35% of revenue\",   # Product mix\n                \"Average transaction value increased 8%\" # Customer behavior\n            ]\n        }\n\n# ğŸ“Š STEP 3: Create tool instances (agent's \"toolbox\")\ntools = [DatabaseQueryTool(), DataAnalysisTool()]\n\n# ğŸ“º STEP 4: Demonstrate tool use\nprint(\"AVAILABLE TOOLS:\")\nprint(\"=\"*70)\nfor tool in tools:\n    print(f\"\\n{tool.name}: {tool.description}\")\n    \n    # Execute tool with empty parameters (just for demonstration)\n    result = tool.execute({})\n    \n    # Display result in formatted JSON\n    print(f\"Sample Output: {json.dumps(result, indent=2)}\")\n\n# ğŸ’¡ KEY INSIGHT - FUNCTION CALLING:\n# Modern LLMs (GPT-4, Claude) have \"function calling\" capabilities:\n# 1. You provide tool descriptions to the LLM\n# 2. LLM decides WHICH tool to use and WITH WHAT PARAMETERS\n# 3. Your code executes the tool\n# 4. You return the result to the LLM\n# 5. LLM processes the result and decides next action\n#\n# Example LLM reasoning:\n# \"User wants Q4 sales data â†’ I should use 'database_query' tool\"\n# \"I got raw data â†’ Now I should use 'data_analysis' tool\"\n# \"I have insights â†’ Now I can answer the user's question\"\n#\n# ğŸ“ PRODUCTION TOOL EXAMPLES:\n# â€¢ Web search (SerpAPI, Google Search API)\n# â€¢ Email (SendGrid, Gmail API)\n# â€¢ Calendar (Google Calendar, Outlook)\n# â€¢ CRM (Salesforce API, HubSpot)\n# â€¢ Code execution (Python REPL, Jupyter)\n# â€¢ File operations (read, write, delete)\n#\n# ğŸ’° SECURITY CONSIDERATION:\n# Tools can take real actions (send emails, delete data, charge credit cards).\n# CRITICAL to implement:\n# â€¢ Authentication (who can use which tools?)\n# â€¢ Authorization (what actions are allowed?)\n# â€¢ Audit logging (track all tool use)\n# â€¢ Rate limiting (prevent abuse)\n# â€¢ Human-in-the-loop for high-risk actions (e.g., financial transactions)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Memory\n",
    "\n",
    "How agents store and retrieve information.\n",
    "\n",
    "**Memory Types:**\n",
    "- **Short-term (Working)**: Current task context\n",
    "- **Long-term (Episodic)**: Past interactions and experiences\n",
    "- **Semantic**: General knowledge and facts\n",
    "- **Procedural**: How to perform tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# AGENT MEMORY: Storing and Retrieving Information\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Show how agents remember past interactions and learned information\n#\n# WHY MEMORY MATTERS:\n# Without memory, every interaction starts from scratch. Memory enables:\n# â€¢ Context awareness (remember previous conversation turns)\n# â€¢ Learning (store successful strategies)\n# â€¢ Personalization (remember user preferences)\n# â€¢ Efficiency (don't re-query the same information)\n#\n# ğŸ“š TYPES OF MEMORY (inspired by human cognition):\n# â€¢ SHORT-TERM: Recent interactions (like working memory)\n# â€¢ LONG-TERM: Persistent knowledge and facts (like episodic memory)\n# â€¢ PROCEDURAL: How to perform tasks (learned behaviors)\n\n# ğŸ“ STEP 1: Define agent memory system\nclass AgentMemory:\n    \"\"\"Simple agent memory system with short-term and long-term storage.\"\"\"\n    \n    def __init__(self):\n        self.short_term = []   # Recent interactions (limited size)\n        self.long_term = {}    # Persistent knowledge (key-value pairs)\n        self.procedural = {}   # Learned procedures (not used in this example)\n    \n    def add_short_term(self, interaction: Dict):\n        \"\"\"\n        Add interaction to short-term memory.\n        \n        Args:\n            interaction: Dict describing what just happened\n                        (e.g., {\"action\": \"query_database\", \"result\": \"success\"})\n        \"\"\"\n        self.short_term.append(interaction)\n        \n        # Keep only last 10 interactions (prevent memory overflow)\n        # In production: more sophisticated management (summarization, importance scoring)\n        if len(self.short_term) > 10:\n            self.short_term.pop(0)  # Remove oldest interaction\n    \n    def store_long_term(self, key: str, value: any):\n        \"\"\"\n        Store information in long-term memory.\n        \n        Args:\n            key: Identifier for the information (e.g., \"user_preference\")\n            value: The information to store (e.g., \"detailed_reports\")\n        \"\"\"\n        self.long_term[key] = value\n    \n    def recall(self, key: str) -> Optional[any]:\n        \"\"\"\n        Retrieve information from long-term memory.\n        \n        Args:\n            key: Identifier to look up\n            \n        Returns:\n            The stored value, or None if not found\n        \"\"\"\n        return self.long_term.get(key)\n    \n    def get_context(self) -> str:\n        \"\"\"Get summary of current context from short-term memory.\"\"\"\n        if not self.short_term:\n            return \"No recent context\"\n        return f\"Last {len(self.short_term)} interactions recorded\"\n\n# ğŸ“Š STEP 2: Demonstrate memory usage\nmemory = AgentMemory()\n\n# Simulate agent actions being added to short-term memory:\nmemory.add_short_term({\"action\": \"query_database\", \"result\": \"success\"})\nmemory.add_short_term({\"action\": \"analyze_data\", \"result\": \"success\"})\n\n# Store learned preferences in long-term memory:\nmemory.store_long_term(\"user_preference\", \"detailed_reports\")\nmemory.store_long_term(\"region\", \"Northeast\")\n\n# ğŸ“º STEP 3: Display memory state\nprint(\"AGENT MEMORY STATE:\")\nprint(\"=\"*70)\nprint(f\"Context: {memory.get_context()}\")\nprint(f\"\\nLong-term Memory:\")\nfor key, value in memory.long_term.items():\n    print(f\"  {key}: {value}\")\nprint(f\"\\nShort-term Memory: {len(memory.short_term)} recent interactions\")\n\n# ğŸ’¡ KEY INSIGHT - MEMORY IN PRODUCTION AGENTS:\n#\n# SHORT-TERM MEMORY (Conversation Buffer):\n# â€¢ In LangChain: ConversationBufferMemory, ConversationSummaryMemory\n# â€¢ Stores recent chat history\n# â€¢ Passed to LLM with each new query\n# â€¢ Trade-off: More history = better context but higher token costs\n#\n# LONG-TERM MEMORY (Vector Database):\n# â€¢ In production: Pinecone, Weaviate, ChromaDB\n# â€¢ Stores embeddings of past conversations, documents, facts\n# â€¢ Agent can search for relevant past information\n# â€¢ Example: \"What did the user say about Q4 sales last week?\"\n#\n# ğŸ“ ADVANCED MEMORY PATTERNS:\n#\n# 1. ENTITY MEMORY: Track facts about specific entities\n#    Example: {\"customer_123\": {\"name\": \"Acme Corp\", \"status\": \"VIP\"}}\n#\n# 2. SUMMARY MEMORY: Summarize old conversations to save tokens\n#    Example: \"User is interested in Northeast sales data for Q4 2024\"\n#\n# 3. KNOWLEDGE GRAPH: Store relationships between entities\n#    Example: Acme Corp â†’ located in â†’ Northeast â†’ has sales â†’ $5.2M\n#\n# ğŸ’° COST-PERFORMANCE TRADE-OFF:\n# â€¢ No memory: Cheapest, but poor user experience\n# â€¢ Buffer memory (last 10 msgs): Moderate cost, good for most cases\n# â€¢ Full history: Expensive (thousands of tokens), best for complex tasks\n# â€¢ Summary memory: Best balance (compressed history)\n#\n# ğŸ¯ REAL-WORLD EXAMPLE:\n# Customer service agent remembers:\n# â€¢ Short-term: \"User asked about refund policy 2 messages ago\"\n# â€¢ Long-term: \"This user prefers email over phone communication\"\n# â€¢ Procedural: \"For refunds over $500, always escalate to supervisor\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The Perception-Action Loop\n",
    "\n",
    "The fundamental cycle of agent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Visual Comparison: ReAct vs Traditional Approaches\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚         TRADITIONAL CHAIN vs REACT FRAMEWORK                        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nTRADITIONAL CHAIN (Linear):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Step 1  â”‚ â”€â”€â†’â”‚ Step 2  â”‚ â”€â”€â†’â”‚ Step 3  â”‚ â”€â”€â†’â”‚  Done   â”‚\nâ”‚  Query  â”‚    â”‚ Retrieveâ”‚    â”‚Generate â”‚    â”‚ Answer  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nProblem: Can't adapt if initial retrieval is insufficient\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nREACT FRAMEWORK (Iterative):\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. THOUGHT   â”‚  \"I need sales data for Q4\"\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 2. ACTION    â”‚  query_database(\"Q4 2024 sales\")\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 3. OBSERVE   â”‚  Result: 1250 transactions, $5.2M revenue\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 4. THOUGHT   â”‚  \"Need breakdown by product\"\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 5. ACTION    â”‚  analyze_by_product(sales_data)\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 6. OBSERVE   â”‚  Product A: 35%, Product B: 28%, Product C: 37%\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 7. THOUGHT   â”‚  \"Sufficient data, ready to answer\"\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 8. FINISH    â”‚  Final answer with breakdown\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nAdvantage: Adapts based on intermediate results\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCOMPARISON METRICS (from Yao et al., 2022):\n\nTask Type           | Traditional | ReAct  | Improvement\n--------------------|-------------|--------|------------\nHotpotQA (reasoning)| 28%         | 47%    | +68%\nFEVER (fact check)  | 72%         | 84%    | +17%\nWebShop (navigation)| 45%         | 78%    | +73%\n\nKey: ReAct excels when multiple steps of reasoning required\n```\n\n> ğŸ’¡ **Why This Matters for Business**: \n> - Traditional: Works for simple, predictable queries\n> - ReAct: Handles complex, multi-step business problems where the path isn't known upfront\n> - Example: \"Analyze declining sales\" requires discovering what dimensions to analyze\n\n---\n\n### Agent Architecture Evolution\n\n```\nEVOLUTION OF AGENT COMPLEXITY\n\nLevel 1: REFLEX AGENT (Rule-Based)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ IF condition THEN action             â”‚\nâ”‚ â€¢ Fast                                â”‚\nâ”‚ â€¢ Predictable                         â”‚\nâ”‚ â€¢ No learning                         â”‚\nâ”‚ Example: \"If temp > 75Â°F, AC on\"     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nLevel 2: MODEL-BASED AGENT (State Tracking)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Track internal state + environment   â”‚\nâ”‚ â€¢ Memory of past                      â”‚\nâ”‚ â€¢ Handles partial observability       â”‚\nâ”‚ â€¢ Still rule-based decisions          â”‚\nâ”‚ Example: Inventory management system â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nLevel 3: GOAL-BASED AGENT (Planning)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Explicit goals + planning             â”‚\nâ”‚ â€¢ Multi-step reasoning                â”‚\nâ”‚ â€¢ Evaluates future states             â”‚\nâ”‚ â€¢ Chooses best path                   â”‚\nâ”‚ Example: Route planning, scheduling   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nLevel 4: UTILITY-BASED AGENT (Optimization)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Optimize utility function             â”‚\nâ”‚ â€¢ Trade-off decisions                 â”‚\nâ”‚ â€¢ Balances multiple objectives        â”‚\nâ”‚ â€¢ Quantifies preferences              â”‚\nâ”‚ Example: Resource allocation          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nLevel 5: LEARNING AGENT (Adaptive)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Learns from experience                â”‚\nâ”‚ â€¢ Performance improves over time      â”‚\nâ”‚ â€¢ Adapts to changing environment      â”‚\nâ”‚ â€¢ Discovers new strategies            â”‚\nâ”‚ Example: Recommendation systems       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nLevel 6: REACT/AGENTIC (Reasoning + Acting)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Interleaved thinking and acting       â”‚\nâ”‚ â€¢ Transparent reasoning               â”‚\nâ”‚ â€¢ Tool use                            â”‚\nâ”‚ â€¢ Self-corrects                       â”‚\nâ”‚ â€¢ Handles complexity                  â”‚\nâ”‚ Example: Research assistant, analyst  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nğŸ¯ Business Decision: Match complexity to need\nâ€¢ Don't use Level 6 for Level 1 problems\nâ€¢ Recognize when simple rules won't suffice\n```\n\n> ğŸ“Š **Visual Learning Tip**: Print this diagram and use it to classify your organization's automation. Where are you over-engineering? Where are you under-powered?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# PERCEPTION-ACTION LOOP: The Fundamental Agent Cycle\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Demonstrate the core perception-action cycle that drives agent behavior\n#\n# WHY THIS LOOP MATTERS:\n# All intelligent agents (human or AI) follow this pattern:\n# 1. PERCEIVE: Understand current state of environment\n# 2. REASON: Think about what to do\n# 3. PLAN: Decide on next action\n# 4. ACT: Execute the action\n# 5. OBSERVE: See what happened\n# 6. REPEAT: Loop back to step 1\n#\n# This is how agents handle dynamic, multi-step tasks!\n\n# ğŸ“ STEP 1: Define the perception-action loop\nclass AgentLoop:\n    \"\"\"Simplified perception-action loop demonstrating core agent behavior.\"\"\"\n    \n    def __init__(self, name: str):\n        self.name = name                    # Agent identifier\n        self.memory = AgentMemory()         # Memory system (defined earlier)\n        self.iteration = 0                  # Track how many cycles completed\n    \n    def perceive(self, environment_state: Dict) -> Dict:\n        \"\"\"\n        PERCEIVE: Understand current environment state.\n        \n        Args:\n            environment_state: Current state of the environment\n                              (e.g., {\"task_complete\": False, \"next_step\": \"query\"})\n        \n        Returns:\n            Perception dictionary with state + context\n        \"\"\"\n        perception = {\n            \"iteration\": self.iteration,\n            \"state\": environment_state,\n            \"context\": self.memory.get_context()  # Add memory context\n        }\n        return perception\n    \n    def reason_and_plan(self, perception: Dict) -> Dict:\n        \"\"\"\n        REASON & PLAN: Decide what to do based on perception.\n        \n        In production, this is where the LLM reasons about:\n        â€¢ What has been accomplished so far?\n        â€¢ What still needs to be done?\n        â€¢ What's the best next action?\n        \n        Args:\n            perception: Current perception of environment\n            \n        Returns:\n            Plan dictionary with action and reasoning\n        \"\"\"\n        # Simplified reasoning (in production: LLM does this)\n        if perception['state'].get('task_complete', False):\n            return {\n                \"action\": \"finish\",\n                \"reason\": \"Task completed\"\n            }\n        else:\n            return {\n                \"action\": \"continue\",\n                \"reason\": \"More work needed\",\n                \"next_step\": perception['state'].get('next_step', 'unknown')\n            }\n    \n    def act(self, plan: Dict) -> Dict:\n        \"\"\"\n        ACT: Execute the planned action.\n        \n        Args:\n            plan: The plan from reason_and_plan()\n            \n        Returns:\n            Result of the action\n        \"\"\"\n        result = {\n            \"action_taken\": plan['action'],\n            \"outcome\": \"success\" if plan['action'] == \"finish\" else \"in_progress\"\n        }\n        \n        # Store action in memory for future reference\n        self.memory.add_short_term(result)\n        \n        return result\n    \n    def run_cycle(self, environment_state: Dict) -> Dict:\n        \"\"\"\n        Run one complete perception-action cycle.\n        \n        This is the heart of the agent: perceive â†’ reason â†’ act\n        \n        Args:\n            environment_state: Current environment state\n            \n        Returns:\n            Result of this cycle\n        \"\"\"\n        self.iteration += 1\n        \n        print(f\"\\n--- Cycle {self.iteration} ---\")\n        \n        # STEP 1: PERCEIVE\n        perception = self.perceive(environment_state)\n        print(f\"Perceive: {perception['state']}\")\n        \n        # STEP 2: REASON AND PLAN\n        plan = self.reason_and_plan(perception)\n        print(f\"Plan: {plan}\")\n        \n        # STEP 3: ACT\n        result = self.act(plan)\n        print(f\"Act: {result}\")\n        \n        return result\n\n# ğŸ“Š STEP 2: Demonstrate the loop with a multi-cycle example\nagent = AgentLoop(\"SalesAnalysisAgent\")\n\nprint(\"PERCEPTION-ACTION LOOP DEMONSTRATION\")\nprint(\"=\"*70)\nprint(\"Watch how the agent perceives, reasons, and acts in each cycle:\")\n\n# CYCLE 1: Agent perceives it needs to query database\nresult1 = agent.run_cycle({\n    \"task_complete\": False,\n    \"next_step\": \"query_database\"\n})\n\n# CYCLE 2: Agent perceives it needs to analyze results\nresult2 = agent.run_cycle({\n    \"task_complete\": False,\n    \"next_step\": \"analyze_results\"\n})\n\n# CYCLE 3: Agent perceives task is complete\nresult3 = agent.run_cycle({\n    \"task_complete\": True\n})\n\n# ğŸ’¡ KEY INSIGHT - WHY THIS IS POWERFUL:\n#\n# TRADITIONAL AUTOMATION:\n# â€¢ Fixed sequence: Step 1 â†’ Step 2 â†’ Step 3 â†’ Done\n# â€¢ Can't adapt if step 2 reveals step 3 is unnecessary\n# â€¢ Can't handle unexpected states\n#\n# PERCEPTION-ACTION LOOP:\n# â€¢ After each action, agent RE-PERCEIVES the environment\n# â€¢ Can adapt based on what happened: \"Step 2 gave me what I need, skip to final report\"\n# â€¢ Can handle unexpected states: \"Error in step 2? Try alternative approach\"\n#\n# ğŸ“ REAL-WORLD EXAMPLES:\n#\n# Example 1: Customer Service Agent\n# Cycle 1: Perceive customer angry â†’ Reason: need empathy â†’ Act: apologize\n# Cycle 2: Perceive customer calmer â†’ Reason: can solve problem â†’ Act: offer solution\n# Cycle 3: Perceive customer satisfied â†’ Reason: task done â†’ Act: close ticket\n#\n# Example 2: Research Agent\n# Cycle 1: Perceive: need market data â†’ Reason: search web â†’ Act: web search\n# Cycle 2: Perceive: found general info â†’ Reason: need specifics â†’ Act: search industry reports\n# Cycle 3: Perceive: have enough data â†’ Reason: can synthesize â†’ Act: write report\n#\n# ğŸ’° IMPLEMENTATION NOTE:\n# Each cycle typically involves:\n# â€¢ 1 LLM call for reasoning (GPT-4: ~$0.03 per 1K tokens)\n# â€¢ Tool execution (database query, API call, etc.)\n# â€¢ Total: $0.05-0.15 per cycle depending on context size\n#\n# Balance: More cycles = more adaptive, but higher cost\n# Typical: 3-7 cycles for complex tasks"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The ReAct Framework\n",
    "\n",
    "**ReAct** = **Rea**soning + **Act**ing\n",
    "\n",
    "A powerful framework that interleaves reasoning (thinking) and acting (tool use).\n",
    "\n",
    "### Key Idea:\n",
    "Instead of just taking actions OR just reasoning, alternate between:\n",
    "1. **Thought**: Reason about what to do next\n",
    "2. **Action**: Execute a specific tool/action\n",
    "3. **Observation**: Observe the result\n",
    "4. **Repeat** until goal is achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# REACT FRAMEWORK: Reasoning + Acting (The Game-Changer)\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Demonstrate the ReAct framework that combines reasoning with action\n#\n# WHY REACT IS REVOLUTIONARY:\n# Traditional chain: Query â†’ Get Result â†’ Answer (no adaptation)\n# ReAct: Think â†’ Act â†’ Observe â†’ Think â†’ Act â†’ Observe... (adaptive!)\n#\n# KEY DIFFERENCE: ReAct makes reasoning EXPLICIT and VISIBLE\n# You can see WHY the agent chose each action!\n#\n# ğŸ“š REFERENCE: Yao et al., 2022 - \"ReAct: Synergizing Reasoning and Acting\"\n#              Showed 50%+ improvement on complex reasoning tasks\n\n# ğŸ“ STEP 1: Implement ReAct agent\nclass ReActAgent:\n    \"\"\"Agent following ReAct pattern: interleaved reasoning and acting.\"\"\"\n    \n    def __init__(self, tools: List[Tool]):\n        # Create tool dictionary for fast lookup by name\n        self.tools = {tool.name: tool for tool in tools}\n        \n        # Track full reasoning trace (Thought â†’ Action â†’ Observation)\n        self.trace = []\n    \n    def think(self, goal: str, observations: List[str]) -> Dict:\n        \"\"\"\n        REASONING STEP: Think about what to do next.\n        \n        In production, this is a prompt to an LLM like:\n        \"Given goal: {goal}\n         Observations so far: {observations}\n         What should I do next? Think step by step.\"\n        \n        Here we simulate with simple logic.\n        \n        Args:\n            goal: The objective to achieve\n            observations: Results from previous actions\n            \n        Returns:\n            Dict with thought, action to take, and action parameters\n        \"\"\"\n        # ğŸ§  REASONING LOGIC (simulated - LLM does this in production):\n        \n        if not observations:\n            # No observations yet â†’ need to get data first\n            return {\n                \"thought\": \"I need to first query the database to get sales data\",\n                \"action\": \"database_query\",\n                \"action_input\": {\"query\": \"Q4 2024 Northeast sales\"}\n            }\n        \n        elif len(observations) == 1:\n            # Have raw data â†’ need to analyze it\n            return {\n                \"thought\": \"I have the raw data, now I need to analyze it\",\n                \"action\": \"data_analysis\",\n                \"action_input\": {\"data\": \"sales_data\"}\n            }\n        \n        else:\n            # Have data + analysis â†’ can finish\n            return {\n                \"thought\": \"I have analyzed the data, task is complete\",\n                \"action\": \"finish\",\n                \"action_input\": {\"final_answer\": \"Analysis complete\"}\n            }\n    \n    def act(self, action: str, action_input: Dict) -> str:\n        \"\"\"\n        ACTION STEP: Execute the chosen tool.\n        \n        Args:\n            action: Name of tool to use\n            action_input: Parameters for the tool\n            \n        Returns:\n            String representation of tool result\n        \"\"\"\n        # Special case: \"finish\" means we're done\n        if action == \"finish\":\n            return action_input[\"final_answer\"]\n        \n        # Look up the tool\n        tool = self.tools.get(action)\n        if not tool:\n            return f\"Error: Tool {action} not found\"\n        \n        # Execute the tool\n        result = tool.execute(action_input)\n        \n        # Return formatted result\n        return json.dumps(result)\n    \n    def run(self, goal: str, max_steps: int = 5) -> List[Dict]:\n        \"\"\"\n        Run the ReAct loop: Think â†’ Act â†’ Observe â†’ Repeat\n        \n        Args:\n            goal: The objective to achieve\n            max_steps: Maximum iterations (safety limit)\n            \n        Returns:\n            Complete trace of thoughts, actions, and observations\n        \"\"\"\n        observations = []\n        \n        for step in range(max_steps):\n            # ğŸ§  THINK: What should I do next?\n            decision = self.think(goal, observations)\n            self.trace.append({\n                \"type\": \"thought\",\n                \"content\": decision[\"thought\"]\n            })\n            \n            # ğŸ› ï¸ ACT: Execute the chosen action\n            self.trace.append({\n                \"type\": \"action\",\n                \"action\": decision[\"action\"],\n                \"input\": decision[\"action_input\"]\n            })\n            \n            # Execute and get result\n            observation = self.act(decision[\"action\"], decision[\"action_input\"])\n            \n            # ğŸ‘ï¸ OBSERVE: What happened?\n            self.trace.append({\n                \"type\": \"observation\",\n                \"content\": observation\n            })\n            observations.append(observation)\n            \n            # Check if we're done\n            if decision[\"action\"] == \"finish\":\n                break\n        \n        return self.trace\n\n# ğŸ“Š STEP 2: Run ReAct agent on example task\ntools = [DatabaseQueryTool(), DataAnalysisTool()]\nreact_agent = ReActAgent(tools)\n\nprint(\"\\nREACT FRAMEWORK DEMONSTRATION\")\nprint(\"=\"*70)\nprint(\"Notice the explicit reasoning at each step:\\n\")\n\n# Execute the agent\ntrace = react_agent.run(\"Analyze Q4 2024 sales for Northeast region\")\n\n# ğŸ“º STEP 3: Display the complete reasoning trace\nfor i, entry in enumerate(trace, 1):\n    if entry[\"type\"] == \"thought\":\n        print(f\"\\nğŸ’­ Thought: {entry['content']}\")\n    elif entry[\"type\"] == \"action\":\n        print(f\"ğŸ› ï¸  Action: {entry['action']}({entry['input']})\")\n    elif entry[\"type\"] == \"observation\":\n        # Truncate long observations for readability\n        obs = entry['content']\n        if len(obs) > 100:\n            obs = obs[:100] + \"...\"\n        print(f\"ğŸ‘ï¸  Observation: {obs}\")\n\n# ğŸ’¡ KEY INSIGHT - WHY REACT OUTPERFORMS TRADITIONAL APPROACHES:\n#\n# TRADITIONAL CHAIN (no reasoning):\n# Query DB â†’ Analyze â†’ Answer\n# Problem: What if the query was wrong? No way to course-correct!\n#\n# REACT (explicit reasoning):\n# Think: \"Need data\" â†’ Query DB â†’ Observe: \"Got data\"\n# Think: \"Need analysis\" â†’ Analyze â†’ Observe: \"Got insights\"  \n# Think: \"Can answer now\" â†’ Finish\n# Advantage: Can adapt based on intermediate results!\n#\n# ğŸ“Š PERFORMANCE GAINS (from Yao et al., 2022 paper):\n# â€¢ HotpotQA (multi-hop reasoning): 28% â†’ 47% (+68% improvement)\n# â€¢ FEVER (fact verification): 72% â†’ 84% (+17% improvement)\n# â€¢ WebShop (web navigation): 45% â†’ 78% (+73% improvement)\n#\n# ğŸ“ WHY THE IMPROVEMENT?\n# 1. TRANSPARENT: Can see agent's reasoning (debug when wrong)\n# 2. ADAPTIVE: Can change approach based on intermediate results\n# 3. GROUNDED: Each thought is followed by action, reducing hallucination\n# 4. RECOVERABLE: Can detect errors and try alternatives\n#\n# ğŸ¯ BUSINESS APPLICATIONS:\n#\n# Example 1: Customer Service\n# Thought: \"Customer seems frustrated\" â†’ Action: Check order status\n# Observation: \"Order delayed 3 days\" â†’ Thought: \"Should offer compensation\"\n# Action: Generate apology email with discount code\n#\n# Example 2: Market Research\n# Thought: \"Need competitor pricing\" â†’ Action: Web search for Company A\n# Observation: \"Found pricing page\" â†’ Thought: \"Need more competitors\"\n# Action: Search Company B â†’ ... â†’ Thought: \"Have 5 competitors, can analyze\"\n# Action: Generate comparison report\n#\n# ğŸ’° COST CONSIDERATION:\n# More explicit reasoning = more tokens = higher cost\n# BUT: Better results mean fewer retries, so often cheaper overall!\n# Typical: $0.10-0.30 per ReAct task vs $0.05-0.10 for simple chain\n# ROI: Worth it for complex, high-value tasks"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Agent Architectures Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# AGENT ARCHITECTURES: Choosing the Right Design Pattern\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Compare different agent architectures and when to use each\n#\n# WHY ARCHITECTURE MATTERS:\n# Not all tasks need the most sophisticated agent!\n# â€¢ Over-engineering: Wasted cost and complexity\n# â€¢ Under-engineering: Poor performance and failures\n# â€¢ Right-sizing: Match architecture to task complexity\n\n# ğŸ“Š BUILD ARCHITECTURE COMPARISON DATA:\narchitectures = {\n    'Architecture': [\n        'Simple Reflex',        # Level 1: Basic if-then rules\n        'Model-Based',          # Level 2: Track internal state\n        'Goal-Based',           # Level 3: Plan toward goals\n        'Utility-Based',        # Level 4: Optimize utility\n        'Learning Agent',       # Level 5: Improve over time\n        'ReAct',                # Level 6: Reasoning + acting\n        'Multi-Agent'           # Level 7: Coordinated agents\n    ],\n    'Key Characteristic': [\n        'Condition-action rules',          # IF condition THEN action\n        'Internal state model',            # Track what happened before\n        'Explicit goal pursuit',           # Plan steps to achieve goal\n        'Maximizes utility function',      # Optimize across objectives\n        'Improves from experience',        # Learn patterns over time\n        'Interleaves reasoning & acting',  # Think â†’ Act â†’ Observe loop\n        'Multiple cooperating agents'      # Specialized agents collaborate\n    ],\n    'Best For': [\n        'Simple, fully observable tasks',           # Everything is visible\n        'Partially observable environments',        # Can't see everything at once\n        'Complex goal achievement',                 # Multi-step objectives\n        'Trade-off decisions',                      # Balancing multiple factors\n        'Improving over time',                      # Pattern recognition\n        'Complex reasoning + tool use',             # Research, analysis tasks\n        'Distributed, specialized tasks'            # Cross-functional workflows\n    ],\n    'Business Example': [\n        'Alert on threshold breach',                # temp > 75Â°F â†’ send alert\n        'Inventory management',                     # Track stock levels over time\n        'Project planning',                         # Create Gantt chart to meet deadline\n        'Resource allocation',                      # Balance cost, speed, quality\n        'Customer preference learning',             # Recommend based on history\n        'Research & analysis tasks',                # Market research, due diligence\n        'Cross-functional workflows'                # Order-to-cash process\n    ]\n}\n\n# ğŸ“‹ CONVERT TO DATAFRAME:\ndf_arch = pd.DataFrame(architectures)\n\n# ğŸ“º DISPLAY ARCHITECTURE COMPARISON:\nprint(\"\\nAGENT ARCHITECTURES\")\nprint(\"=\"*70)\nfor idx, row in df_arch.iterrows():\n    print(f\"\\n{row['Architecture']}:\")\n    print(f\"  Characteristic: {row['Key Characteristic']}\")\n    print(f\"  Best For: {row['Best For']}\")\n    print(f\"  Example: {row['Business Example']}\")\n\n# ğŸ’¡ DECISION FRAMEWORK - CHOOSING THE RIGHT ARCHITECTURE:\nprint(\"\\n\" + \"=\"*70)\nprint(\"ARCHITECTURE SELECTION GUIDE\")\nprint(\"=\"*70)\n\ndecision_guide = \"\"\"\nAsk yourself these questions:\n\n1ï¸âƒ£  Can you write simple IF-THEN rules?\n   â†’ YES: Use Simple Reflex (cheapest, fastest)\n   â†’ NO: Continue to question 2\n\n2ï¸âƒ£  Do you need to track state over time?\n   â†’ YES: Use Model-Based (e.g., inventory tracking)\n   â†’ NO: Continue to question 3\n\n3ï¸âƒ£  Does the task require multi-step planning?\n   â†’ YES: Continue to question 4\n   â†’ NO: Re-evaluate - might still be automation\n\n4ï¸âƒ£  Do you need to balance competing objectives?\n   â†’ YES: Use Utility-Based (e.g., cost vs speed vs quality)\n   â†’ NO: Use Goal-Based (single clear objective)\n\n5ï¸âƒ£  Should performance improve over time?\n   â†’ YES: Use Learning Agent (recommendations, predictions)\n   â†’ NO: Static behavior is acceptable\n\n6ï¸âƒ£  Do you need transparent reasoning?\n   â†’ YES: Use ReAct (audit trails, debugging, compliance)\n   â†’ NO: Goal-Based or Utility-Based sufficient\n\n7ï¸âƒ£  Does the task involve multiple specialized sub-tasks?\n   â†’ YES: Use Multi-Agent (cross-functional workflows)\n   â†’ NO: Single agent sufficient\n\"\"\"\n\nprint(decision_guide)\n\n# ğŸ“ ARCHITECTURE EVOLUTION IN PRACTICE:\nprint(\"\\n\" + \"=\"*70)\nprint(\"TYPICAL EVOLUTION PATH\")\nprint(\"=\"*70)\n\nevolution = \"\"\"\nStage 1: PROTOTYPE (week 1-2)\nâ€¢ Start with Simple Reflex or basic Goal-Based\nâ€¢ Validate the use case quickly\nâ€¢ Cost: Low ($100-500)\n\nStage 2: PILOT (month 1-2)\nâ€¢ Upgrade to ReAct for better reasoning\nâ€¢ Add memory and context handling\nâ€¢ Cost: Medium ($1K-5K)\n\nStage 3: PRODUCTION (month 3-6)\nâ€¢ Add learning capabilities if needed\nâ€¢ Implement multi-agent if handling complex workflows\nâ€¢ Cost: Higher ($10K-50K+)\n\nLESSON: Start simple, add complexity only when validated!\n\"\"\"\n\nprint(evolution)\n\n# ğŸ’° COST COMPARISON (typical ranges):\nprint(\"\\n\" + \"=\"*70)\nprint(\"APPROXIMATE COST PER TASK\")\nprint(\"=\"*70)\n\ncosts = {\n    'Architecture': ['Simple Reflex', 'Model-Based', 'Goal-Based', \n                    'Utility-Based', 'Learning', 'ReAct', 'Multi-Agent'],\n    'Cost per Task': ['$0.001', '$0.01', '$0.05-0.10', \n                     '$0.10-0.20', '$0.05-0.30', '$0.10-0.50', '$0.50-2.00'],\n    'When Worth It': [\n        'High volume, simple tasks (1000s/day)',\n        'Moderate volume with state (100s/day)',\n        'Complex planning (10s-100s/day)',\n        'Optimization required (10s/day)',\n        'Long-term value from learning',\n        'High-value decisions ($1000+ impact)',\n        'Mission-critical workflows'\n    ]\n}\n\ndf_costs = pd.DataFrame(costs)\nprint(df_costs.to_string(index=False))\n\n# ğŸ¯ KEY TAKEAWAY:\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ’¡ GOLDEN RULE: Use the simplest architecture that works!\")\nprint(\"   â€¢ Saves money (fewer LLM calls)\")\nprint(\"   â€¢ Faster execution (less reasoning overhead)\")\nprint(\"   â€¢ Easier debugging (fewer moving parts)\")\nprint(\"   â€¢ Better reliability (fewer points of failure)\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Business Applications of Agentic Systems\n",
    "\n",
    "Where agentic capabilities add the most value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# BUSINESS APPLICATIONS: Where Agentic Capabilities Create Value\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Show real business scenarios where agentic AI delivers ROI\n#\n# WHY THIS MATTERS:\n# Helps you identify opportunities in YOUR organization where:\n# â€¢ Automation is too rigid\n# â€¢ Chatbots are too limited\n# â€¢ Agentic capabilities would unlock real value\n\n# ğŸ“Š BUILD BUSINESS SCENARIO DATA:\nbusiness_cases = {\n    'Scenario': [\n        'Complex Customer Inquiry',      # Support beyond FAQ\n        'Market Research',               # Competitive intelligence\n        'Financial Analysis',            # Investment decisions\n        'Supply Chain Optimization',     # Operational efficiency\n        'Competitive Intelligence'       # Strategic awareness\n    ],\n    \n    'Why Agentic?': [\n        # Customer inquiry needs multi-step reasoning:\n        'Multi-step problem solving, tool use, adaptation',\n        \n        # Market research requires dynamic strategy:\n        'Dynamic data gathering, synthesis, reporting',\n        \n        # Financial analysis needs multiple data sources:\n        'Multiple data sources, complex calculations, insights',\n        \n        # Supply chain needs real-time decisions:\n        'Real-time monitoring, planning, decision making',\n        \n        # Competitive intel needs continuous monitoring:\n        'Continuous monitoring, analysis, alerting'\n    ],\n    \n    'Required Capabilities': [\n        # What the agent needs to do:\n        'Knowledge base search, policy checking, personalization',\n        'Web search, data extraction, analysis, synthesis',\n        'Database queries, calculations, trend analysis',\n        'Sensor monitoring, optimization algorithms, alerts',\n        'Web monitoring, comparison, change detection'\n    ],\n    \n    'Value Created': [\n        # Business impact:\n        'Faster resolution, higher satisfaction, 24/7 availability',\n        'Comprehensive insights, time savings, consistency',\n        'Faster decisions, deeper insights, reduced errors',\n        'Cost reduction, efficiency, risk mitigation',\n        'Early awareness, strategic advantage, automation'\n    ]\n}\n\n# ğŸ“º DISPLAY BUSINESS APPLICATIONS:\nprint(\"\\nBUSINESS APPLICATIONS OF AGENTIC SYSTEMS\")\nprint(\"=\"*70)\nfor i, scenario in enumerate(business_cases['Scenario']):\n    print(f\"\\n{scenario}:\")\n    print(f\"  Why Agentic: {business_cases['Why Agentic?'][i]}\")\n    print(f\"  Capabilities: {business_cases['Required Capabilities'][i]}\")\n    print(f\"  Value: {business_cases['Value Created'][i]}\")\n\n# ğŸ’¡ ROI CALCULATION FRAMEWORK:\nprint(\"\\n\" + \"=\"*70)\nprint(\"ROI CALCULATION FRAMEWORK\")\nprint(\"=\"*70)\n\nroi_framework = \"\"\"\nFor each potential use case, calculate:\n\nCOSTS:\n1. Development: $10K-50K (initial agent development)\n2. Infrastructure: $500-2K/month (LLM API, tools, hosting)\n3. Maintenance: $2K-5K/month (monitoring, improvements)\n4. Per-task cost: $0.10-0.50 (LLM + tool calls)\n\nBENEFITS:\n1. Time savings: [hours saved per task] Ã— [hourly rate] Ã— [tasks/month]\n2. Quality improvement: [error reduction %] Ã— [cost of errors]\n3. Scale enablement: [tasks enabled] Ã— [value per task]\n4. Customer satisfaction: [NPS improvement] Ã— [customer lifetime value]\n\nBREAK-EVEN:\nâ€¢ Typical: 3-12 months for high-volume use cases\nâ€¢ Quick wins: <3 months for replacing expensive manual work\nâ€¢ Long-term: >12 months for strategic/learning applications\n\nEXAMPLE: Customer Service Agent\nâ€¢ Handles 1000 inquiries/month\nâ€¢ Replaces 30 min of agent time each â†’ 500 hours/month\nâ€¢ Agent cost: $30/hour â†’ $15,000/month savings\nâ€¢ Agent cost: $0.20 per inquiry â†’ $200/month\nâ€¢ NET SAVINGS: $14,800/month\nâ€¢ PAYBACK: <2 months\n\"\"\"\n\nprint(roi_framework)\n\n# ğŸ“ IDENTIFYING GOOD CANDIDATES:\nprint(\"\\n\" + \"=\"*70)\nprint(\"CHECKLIST: Is This a Good Agentic AI Use Case?\")\nprint(\"=\"*70)\n\nchecklist = \"\"\"\nâœ… GOOD CANDIDATES:\nâ€¢ Task requires 3+ steps that vary by situation\nâ€¢ Human experts currently handle it (knowledge work)\nâ€¢ High volume (10+ occurrences per day)\nâ€¢ Clear success criteria (can measure improvement)\nâ€¢ Access to necessary data/tools\nâ€¢ Tolerance for 80-90% accuracy (not life-critical)\nâ€¢ Can have human oversight for edge cases\n\nâŒ POOR CANDIDATES:\nâ€¢ Can be solved with simple IF-THEN rules\nâ€¢ Requires 100% accuracy (medical diagnosis, legal)\nâ€¢ Very low volume (<5 per month)\nâ€¢ No clear value metric\nâ€¢ Data unavailable or inaccessible\nâ€¢ Highly regulated with no room for AI decisions\nâ€¢ Cheaper to just hire more people\n\nğŸ¤” MAYBE (NEED MORE ANALYSIS):\nâ€¢ Task done infrequently but high value each time\nâ€¢ Accuracy requirements 95-99% (need testing)\nâ€¢ Some data available, some missing\nâ€¢ Regulatory gray area (check with legal/compliance)\nâ€¢ Current process poorly documented (need to map it first)\n\"\"\"\n\nprint(checklist)\n\n# ğŸ¯ ACTION PLAN FOR YOUR ORGANIZATION:\nprint(\"\\n\" + \"=\"*70)\nprint(\"STEP-BY-STEP: Finding Your First Agentic AI Use Case\")\nprint(\"=\"*70)\n\naction_plan = \"\"\"\nSTEP 1: Brainstorm (1 week)\nâ€¢ List 10-20 knowledge work tasks your team does\nâ€¢ For each, ask: \"Could this be automated? What makes it hard?\"\nâ€¢ Focus on tasks people find repetitive but requiring judgment\n\nSTEP 2: Evaluate (1 week)\nâ€¢ Score each task on:\n  - Frequency (how often?)\n  - Value (savings per instance?)\n  - Feasibility (data available? tools exist?)\n  - Risk (what if it fails?)\nâ€¢ Select top 3 candidates\n\nSTEP 3: Validate (2 weeks)\nâ€¢ For top candidate:\n  - Map exact workflow steps\n  - Identify required tools/data\n  - Test with simple prompt (ChatGPT/Claude)\n  - Check if output quality is acceptable\n\nSTEP 4: Pilot (4-8 weeks)\nâ€¢ Build minimal agent (LangChain, OpenAI Assistants, etc.)\nâ€¢ Test on 10-50 real examples\nâ€¢ Measure accuracy, cost, time savings\nâ€¢ Get user feedback\n\nSTEP 5: Scale (2-6 months)\nâ€¢ Refine based on pilot learnings\nâ€¢ Add monitoring, error handling, human-in-loop\nâ€¢ Roll out to full team\nâ€¢ Track ROI metrics\n\nTYPICAL TIMELINE: 3-6 months from idea to production\n\"\"\"\n\nprint(action_plan)\n\n# ğŸ’° FINAL THOUGHT:\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ’¡ Remember: Start with one focused use case.\")\nprint(\"   Success with one agent builds confidence for more ambitious projects.\")\nprint(\"   The learning from your first agent is invaluable!\")\nprint(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hands-On Practice Activity\n",
    "\n",
    "### Design an Agentic System for Your Business\n",
    "\n",
    "Choose a complex task in your organization that would benefit from agentic capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# YOUR TURN: Design Your Agentic System\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Apply what you've learned by designing an agent for YOUR organization\n#\n# ğŸ“ INSTRUCTIONS:\n# Replace the placeholder text below with details about a real use case\n# from your organization. Be as specific as possible!\n#\n# âœ… TIPS FOR SUCCESS:\n# â€¢ Choose a task that's complex but well-understood\n# â€¢ Think about tasks that frustrate your team (repetitive but need judgment)\n# â€¢ Consider what data/tools would be needed\n# â€¢ Be realistic about constraints and risks\n#\n# ğŸ’¡ EXAMPLE STARTER IDEAS:\n# â€¢ Analyze customer feedback and categorize issues\n# â€¢ Research competitors and create comparison reports\n# â€¢ Review contracts and flag risky clauses\n# â€¢ Triage support tickets and route to appropriate team\n# â€¢ Monitor industry news and summarize relevant updates\n\nmy_agent_design = \"\"\"\nTASK DESCRIPTION:\n[Describe a complex task from YOUR organization that requires autonomous behavior]\n\nExample: \"Analyze monthly sales performance across all regions, identify declining \nproducts, research potential causes (competitor actions, seasonality, etc.), and \ngenerate an executive summary with recommended actions.\"\n\nWHY IT NEEDS AGENTIC CAPABILITIES:\n[Explain why simple automation or a chatbot won't work for this task]\n\nExample: \"Can't use automation because the analysis path varies based on what we find. \nIf one region is declining, need to dig deeper into that region. If it's product-wide, \nneed to research market factors. A chatbot can't handle this multi-step investigation.\"\n\nREQUIRED CAPABILITIES:\n1. Perception: [What does the agent need to understand?]\n   Example: \"Sales data structure, regional hierarchies, product categories, time periods\"\n\n2. Planning: [What planning is required?]\n   Example: \"Create analysis plan based on initial findings, decide which dimensions to \n   investigate (region vs product vs time), plan depth of analysis based on severity\"\n\n3. Reasoning: [What decisions must it make?]\n   Example: \"Determine if decline is significant (vs normal variation), decide if external \n   research is needed, prioritize findings by business impact\"\n\n4. Tools: [What tools/data sources does it need?]\n   Example: \"Sales database (SQL), web search for competitor news, industry reports API, \n   charting library for visualizations, email for distribution\"\n\n5. Memory: [What must it remember?]\n   Example: \"Historical analysis patterns (what worked before), user preferences (which \n   metrics matter most), past recommendations and outcomes (learn what works)\"\n\nARCHITECTURE CHOICE:\n[Which architecture would you use and why?]\n\nExample: \"ReAct framework because:\nâ€¢ Need transparent reasoning (executives want to understand the logic)\nâ€¢ Multi-step analysis with adaptation (can't pre-plan all steps)\nâ€¢ Tool use required (database, web search, charts)\nâ€¢ Should be able to explain its thought process\"\n\nEXPECTED VALUE:\n[What business value would this create? Be specific with numbers if possible]\n\nExample: \"Currently takes analyst 4 hours/month = $200/month in labor. \nAgent could reduce to 30 min of review time = $175/month savings.\nMore importantly: Faster insights (hours vs days) could help catch declining \nproducts 2-3 weeks earlier, worth ~$50K in prevented losses annually.\"\n\nRISKS AND MITIGATION:\n[What could go wrong? How would you handle it?]\n\nExample: \"Risks: Wrong conclusions, miss important factors, recommend bad actions\nMitigation: Always have human review before taking action, start with low-stakes \nanalyses, track accuracy over time, require citations for all insights\"\n\"\"\"\n\n# ğŸ“º DISPLAY YOUR DESIGN:\nprint(my_agent_design)\n\n# ğŸ“ REFLECTION QUESTIONS (think about these, discuss with your team):\nreflection_questions = \"\"\"\n1. Is this the SIMPLEST solution? Could a simpler approach work?\n   (Don't build a ReAct agent if automation would suffice!)\n\n2. Do you have access to the required data and tools?\n   (Missing data is the #1 blocker for agent projects)\n\n3. How will you measure success?\n   (Define metrics BEFORE building: accuracy, time saved, user satisfaction)\n\n4. What's your fallback plan if the agent fails?\n   (Always have human backup for critical tasks)\n\n5. Who are the stakeholders? Do they understand what agents can/can't do?\n   (Manage expectations early - agents aren't perfect!)\n\"\"\"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"REFLECTION QUESTIONS:\")\nprint(\"=\"*70)\nprint(reflection_questions)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# YOUR TURN: Create a Simple Plan for Your Agent\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# ğŸ¯ GOAL: Map out the step-by-step reasoning and actions your agent would take\n#\n# ğŸ“ INSTRUCTIONS:\n# Create a multi-step plan showing how your agent would accomplish the task\n# you designed in the previous exercise. Use the ReAct pattern: Think â†’ Act\n#\n# âœ… TIPS:\n# â€¢ Start with 3-5 steps (keep it simple for your first design)\n# â€¢ Each step should have: Thought (why?), Action (what?), Tool (how?)\n# â€¢ Think about what the agent learns from each step\n# â€¢ Consider how it would adapt if things don't go as expected\n#\n# ğŸ’¡ EXAMPLE STRUCTURE:\n# Step 1: Get the data\n# Step 2: Analyze initial results\n# Step 3: Investigate findings (adaptive based on step 2)\n# Step 4: Generate report\n\n# ğŸ“Š YOUR AGENT PLAN:\nmy_agent_plan = [\n    {\n        \"step\": 1,\n        \"thought\": \"[What would the agent think? What question is it trying to answer?]\",\n        # Example: \"I need to get sales data for all regions for the last 3 months\"\n        \n        \"action\": \"[What action would it take? Be specific!]\",\n        # Example: \"Query sales database: SELECT region, product, SUM(revenue) FROM sales \n        #           WHERE date >= '2024-Q3' GROUP BY region, product\"\n        \n        \"tool\": \"[What tool would it use?]\",\n        # Example: \"database_query\"\n        \n        \"expected_observation\": \"[What result would it get?]\"\n        # Example: \"DataFrame with 500 rows showing sales by region and product\"\n    },\n    {\n        \"step\": 2,\n        \"thought\": \"[After seeing step 1 results, what would it think next?]\",\n        # Example: \"I need to identify which regions or products declined vs last quarter\"\n        \n        \"action\": \"[What's the next action?]\",\n        # Example: \"Calculate month-over-month change for each region and product, \n        #           flag any declines >10%\"\n        \n        \"tool\": \"[Which tool?]\",\n        # Example: \"data_analysis\"\n        \n        \"expected_observation\": \"[What would it learn?]\"\n        # Example: \"Northeast region Product A declined 15%, needs investigation\"\n    },\n    {\n        \"step\": 3,\n        \"thought\": \"[How does it adapt based on step 2? This is the KEY to agentic AI!]\",\n        # Example: \"Northeast Product A declined significantly. I should research \n        #           if competitors launched new products in that region.\"\n        \n        \"action\": \"[What adaptive action?]\",\n        # Example: \"Search web for: 'Northeast consumer products launches Q3 2024' \n        #           and 'Product A competitors new releases'\"\n        \n        \"tool\": \"[Which tool?]\",\n        # Example: \"web_search\"\n        \n        \"expected_observation\": \"[What might it find?]\"\n        # Example: \"Competitor launched similar product in Northeast in August 2024\"\n    },\n    {\n        \"step\": 4,\n        \"thought\": \"[Based on accumulated findings, what's the final thought?]\",\n        # Example: \"I have identified the decline (15% in Northeast Product A), \n        #           likely cause (competitor launch), and supporting data. Ready to report.\"\n        \n        \"action\": \"[Final action?]\",\n        # Example: \"Generate executive summary with: declining product, magnitude, \n        #           likely cause, recommendation to investigate competitive response\"\n        \n        \"tool\": \"[Which tool?]\",\n        # Example: \"report_generator\"\n        \n        \"expected_observation\": \"[Final output?]\"\n        # Example: \"2-page executive summary with charts and recommendations\"\n    }\n    # Add more steps if needed for your specific use case!\n    # Typical range: 3-7 steps for most business tasks\n]\n\n# ğŸ“º DISPLAY YOUR PLAN:\nprint(\"MY AGENT PLAN:\")\nprint(\"=\"*70)\nfor step in my_agent_plan:\n    print(f\"\\nStep {step['step']}:\")\n    print(f\"  ğŸ’­ Thought: {step['thought']}\")\n    print(f\"  ğŸ› ï¸  Action: {step['action']}\")\n    print(f\"  ğŸ”§ Tool: {step['tool']}\")\n    print(f\"  ğŸ‘ï¸  Expected: {step.get('expected_observation', 'N/A')}\")\n\n# ğŸ’¡ ADVANCED PLANNING CONSIDERATIONS:\nprint(\"\\n\" + \"=\"*70)\nprint(\"ADVANCED PLANNING: What Could Go Wrong?\")\nprint(\"=\"*70)\n\nerror_handling = \"\"\"\nFor each step in your plan, consider:\n\n1. WHAT IF THE TOOL FAILS?\n   Example: Database query times out\n   â†’ Fallback: Retry with smaller date range, or use cached data\n\n2. WHAT IF THE OBSERVATION IS UNEXPECTED?\n   Example: No declining products found\n   â†’ Adaptation: Expand analysis to look for growth opportunities instead\n\n3. WHAT IF THE AGENT GETS STUCK?\n   Example: Web search returns no relevant results\n   â†’ Fallback: Skip competitive research, note as limitation in report\n\n4. HOW DO YOU KNOW WHEN TO STOP?\n   Example: Agent keeps finding more things to investigate\n   â†’ Stopping condition: Max 5 steps, or when key questions are answered\n\n5. HOW DO YOU PREVENT HALLUCINATION?\n   Example: Agent makes up statistics\n   â†’ Validation: Require citations, cross-check numbers, human review\n\nPRO TIP: Always include a max_steps limit (e.g., 10) to prevent infinite loops!\n\"\"\"\n\nprint(error_handling)\n\n# ğŸ“ VALIDATION CHECKLIST:\nprint(\"\\n\" + \"=\"*70)\nprint(\"VALIDATE YOUR PLAN:\")\nprint(\"=\"*70)\n\nvalidation = \"\"\"\nBefore implementing, ask yourself:\n\nâ–¡ Does each step clearly build on the previous one?\nâ–¡ Are the tools realistic? (Do they exist or can you build them?)\nâ–¡ Is there adaptation? (Does the agent adjust based on findings?)\nâ–¡ Could a human expert follow this plan? (Is it logical?)\nâ–¡ What's the typical path? What are alternative paths?\nâ–¡ How would you test this? (What examples would prove it works?)\nâ–¡ What's the expected cost? (Estimate LLM calls and tool usage)\nâ–¡ What's the time to execute? (Should be <5 min for most business tasks)\n\nIf you can answer \"yes\" to most of these, your plan is solid!\n\"\"\"\n\nprint(validation)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Discussion Questions\n",
    "\n",
    "Consider the following:\n",
    "\n",
    "1. **Agent vs. Automation**: What distinguishes an \"agentic\" system from a standard automation script or a simple chatbot in a business context? Provide an example task where agentic capabilities would be necessary.\n",
    "\n",
    "2. **Autonomy Levels**: How much autonomy should business agents have? Where do you draw the line for requiring human oversight?\n",
    "\n",
    "> ğŸ’¡ **Key Insight**: 3. **Trust and Reliability**: What would make you trust an agentic system to handle important business tasks? What safeguards are needed?\n",
    "\n",
    "4. **Planning Complexity**: For your use case, how many steps ahead should an agent plan? What are the risks of over-planning vs. under-planning?\n",
    "\n",
    "5. **Tool Access**: Which business tools/systems should agents be allowed to access? What access controls are necessary?\n",
    "\n",
    "6. **Failure Modes**: How should an agent behave when it encounters a problem it can't solve? When should it escalate to humans?\n",
    "\n",
    "7. **Value Assessment**: How do you evaluate whether implementing an agentic system is worth the investment vs. simpler alternatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“š Additional Resources & References\n\n### Official Documentation & Frameworks\n\n**LangChain (Python & JavaScript)**\n- [Agents Documentation](https://python.langchain.com/docs/modules/agents/) - Comprehensive agent implementation guide\n- [Agent Types](https://python.langchain.com/docs/modules/agents/agent_types/) - Different agent architectures\n- [Tools](https://python.langchain.com/docs/modules/agents/tools/) - Pre-built tool integrations\n- [GitHub](https://github.com/langchain-ai/langchain) - 75K+ stars\n\n**Microsoft AutoGen**\n- [Documentation](https://microsoft.github.io/autogen/) - Multi-agent conversation framework\n- [Examples](https://github.com/microsoft/autogen/tree/main/notebook) - Jupyter notebooks\n- [Paper](https://arxiv.org/abs/2308.08155) - AutoGen research paper\n\n**OpenAI Assistants API**\n- [Overview](https://platform.openai.com/docs/assistants/overview) - Managed agent infrastructure\n- [Tools](https://platform.openai.com/docs/assistants/tools) - Code Interpreter, Retrieval, Function calling\n- [Playground](https://platform.openai.com/playground) - Interactive testing\n\n**Anthropic Claude**\n- [Tool Use Documentation](https://docs.anthropic.com/claude/docs/tool-use) - Function calling with Claude\n- [Agentic Patterns](https://docs.anthropic.com/claude/docs/agentic-patterns) - Agent design patterns\n\n### Open Source Projects\n\n**Autonomous Agent Projects**\n1. **AutoGPT** - [github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)\n   - 155K+ stars, original autonomous agent experiment\n   - Fully autonomous task completion\n\n2. **BabyAGI** - [github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)\n   - Task-driven autonomous agent\n   - Simple, educational implementation\n\n3. **AgentGPT** - [github.com/reworkd/AgentGPT](https://github.com/reworkd/AgentGPT)\n   - Web-based autonomous agents\n   - Browser-accessible interface\n\n4. **SuperAGI** - [github.com/TransformerOptimus/SuperAGI](https://github.com/TransformerOptimus/SuperAGI)\n   - Open-source AGI infrastructure\n   - Tool creation and management\n\n### Academic Papers & Research\n\n**Foundation Papers**\n1. **Yao, S., et al. (2022).** *ReAct: Synergizing Reasoning and Acting in Language Models.*\n   - [arXiv:2210.03629](https://arxiv.org/abs/2210.03629)\n   - ICLR 2023, foundation of ReAct framework\n\n2. **Xi, Z., et al. (2023).** *The Rise and Potential of Large Language Model Based Agents: A Survey.*\n   - [arXiv:2309.07864](https://arxiv.org/abs/2309.07864)\n   - 160-page comprehensive survey\n\n3. **Wang, L., et al. (2024).** *A Survey on Large Language Model based Autonomous Agents.*\n   - [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)\n   - Recent survey with architecture taxonomy\n\n**Advanced Techniques**\n4. **Park, J. S., et al. (2023).** *Generative Agents: Interactive Simulacra of Human Behavior.*\n   - [arXiv:2304.03442](https://arxiv.org/abs/2304.03442)\n   - Agents with memory, reflection, planning\n\n5. **Shinn, N., et al. (2023).** *Reflexion: Language Agents with Verbal Reinforcement Learning.*\n   - [arXiv:2303.11366](https://arxiv.org/abs/2303.11366)\n   - Self-reflective agents that learn from mistakes\n\n6. **Qian, C., et al. (2023).** *Communicative Agents for Software Development.*\n   - [arXiv:2307.07924](https://arxiv.org/abs/2307.07924)\n   - Multi-agent collaboration for coding\n\n7. **Liu, X., et al. (2023).** *AgentBench: Evaluating LLMs as Agents.*\n   - [arXiv:2308.03688](https://arxiv.org/abs/2308.03688)\n   - Benchmark for evaluating agent capabilities\n\n**Memory & Planning**\n8. **Zhong, W., et al. (2023).** *MemGPT: Towards LLMs as Operating Systems.*\n   - [arXiv:2310.08560](https://arxiv.org/abs/2310.08560)\n   - Hierarchical memory management for agents\n\n9. **Hao, S., et al. (2023).** *Reasoning with Language Model is Planning with World Model.*\n   - [arXiv:2305.14992](https://arxiv.org/abs/2305.14992)\n   - Planning in language-based world models\n\n### Industry Reports & Analysis\n\n**Market Analysis**\n- **Sequoia Capital (2024)**: \"The Rise of AI Agents\" - [sequoiacap.com/ai-agents](https://www.sequoiacap.com/)\n- **Andreessen Horowitz (2024)**: \"The Agentic AI Market\" - [a16z.com/ai-agents](https://a16z.com/)\n- **Gartner (2024)**: \"Emerging Tech: Autonomous AI Agents\" - Hype Cycle positioning\n\n**Company Engineering Blogs**\n- **OpenAI**: [openai.com/blog](https://openai.com/blog) - GPT-4 capabilities, Assistants API\n- **Anthropic**: [anthropic.com/news](https://www.anthropic.com/news) - Claude agent patterns\n- **Google DeepMind**: [deepmind.google/discover/blog](https://deepmind.google/discover/blog/) - Research updates\n- **Microsoft Research**: [microsoft.com/research/blog](https://www.microsoft.com/en-us/research/blog/) - AutoGen and more\n\n### Interactive Learning & Tools\n\n**Agent Development Platforms**\n- [LangSmith](https://www.langchain.com/langsmith) - Debug and monitor agents\n- [AgentOps](https://www.agentops.ai/) - Agent observability platform\n- [Weights & Biases](https://wandb.ai/) - Experiment tracking for agents\n\n**Tutorials & Courses**\n- [DeepLearning.AI - Building AI Agents](https://www.deeplearning.ai/) - Short course on agent development\n- [LangChain Tutorials](https://python.langchain.com/docs/use_cases/agents/) - Step-by-step guides\n- [Hugging Face Agents](https://huggingface.co/docs/transformers/en/agents) - Transformers-based agents\n\n**Community Resources**\n- [LangChain Discord](https://discord.gg/langchain) - Active community, help channel\n- [r/LangChain](https://www.reddit.com/r/LangChain/) - Reddit community\n- [AI Agents Newsletter](https://www.latent.space/) - Weekly updates on agent AI\n\n### Benchmarks & Evaluation\n\n**Agent Benchmarks**\n1. **AgentBench** - [github.com/THUDM/AgentBench](https://github.com/THUDM/AgentBench)\n   - Multi-environment agent evaluation\n\n2. **WebArena** - [webarena.dev](https://webarena.dev/)\n   - Realistic web navigation tasks\n\n3. **SWE-bench** - [swe-bench.github.io](https://swe-bench.github.io/)\n   - Software engineering agent benchmark\n\n4. **GAIA** - General AI Assistants benchmark\n   - Real-world question answering\n\n### Visual Learning Resources\n\n**Video Content**\n- [Andrej Karpathy - State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A) - LLM foundations\n- [LangChain YouTube](https://www.youtube.com/@LangChain) - Tutorial videos\n- [AI Explained](https://www.youtube.com/@aiexplained-official) - Latest research breakdowns\n\n**Interactive Demos**\n- [LangChain Templates](https://github.com/langchain-ai/langchain/tree/master/templates) - Ready-to-deploy examples\n- [AutoGPT Web Demo](https://agentgpt.reworkd.ai/) - Try in browser\n- [ChatGPT with Plugins](https://openai.com/blog/chatgpt-plugins) - Agent-like capabilities\n\n### Books & Long-Form Content\n\n1. **Russell, S. & Norvig, P. (2021).** *Artificial Intelligence: A Modern Approach* (4th ed.)\n   - Chapter 2: Intelligent Agents (foundational theory)\n\n2. **Wooldridge, M. (2020).** *An Introduction to MultiAgent Systems* (2nd ed.)\n   - Academic treatment of multi-agent systems\n\n3. **Sutton, R. & Barto, A. (2018).** *Reinforcement Learning: An Introduction*\n   - Foundation for learning agents\n\n---\n\n## ğŸ”— Quick Links Summary\n\n| Need | Resource | Link |\n|------|----------|------|\n| **Start Building** | LangChain Quickstart | [python.langchain.com/docs/get_started](https://python.langchain.com/docs/get_started/quickstart) |\n| **Understand ReAct** | Original Paper | [arXiv:2210.03629](https://arxiv.org/abs/2210.03629) |\n| **See Examples** | AutoGPT | [github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) |\n| **Latest Research** | Agent Survey (Xi et al.) | [arXiv:2309.07864](https://arxiv.org/abs/2309.07864) |\n| **Production Use** | OpenAI Assistants | [platform.openai.com/docs/assistants](https://platform.openai.com/docs/assistants/overview) |\n| **Multi-Agent** | AutoGen | [microsoft.github.io/autogen](https://microsoft.github.io/autogen/) |\n| **Benchmarks** | AgentBench | [github.com/THUDM/AgentBench](https://github.com/THUDM/AgentBench) |\n\n---\n\n*End of Week 6 Notebook*\n\n> ğŸ“Œ **Citation Note**: All academic papers include arXiv or DOI links. Industry sources verified via official company channels. Resource links checked as of November 2024. For latest updates, check project GitHub repositories and official documentation."
  },
  {
   "cell_type": "markdown",
   "source": "## ğŸ“Œ Quick Reference Guide\n\n### Agentic System Decision Framework\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚          WHEN DO YOU NEED AN AGENTIC SYSTEM?                    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚  âœ… USE AGENTIC AI WHEN:                                        â”‚\nâ”‚                                                                 â”‚\nâ”‚  1. Path to solution isn't predefined                          â”‚\nâ”‚     Example: Customer inquiry could go many directions         â”‚\nâ”‚                                                                 â”‚\nâ”‚  2. Multiple steps required, but sequence varies               â”‚\nâ”‚     Example: Research task - what to search depends on results â”‚\nâ”‚                                                                 â”‚\nâ”‚  3. Contextual decision-making needed                          â”‚\nâ”‚     Example: Choose different tools based on situation         â”‚\nâ”‚                                                                 â”‚\nâ”‚  4. Task requires synthesis of information                     â”‚\nâ”‚     Example: Analyze data from multiple sources                â”‚\nâ”‚                                                                 â”‚\nâ”‚  5. Adaptive behavior adds value                               â”‚\nâ”‚     Example: Learn from feedback to improve                    â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  âŒ DON'T USE AGENTIC AI WHEN:                                  â”‚\nâ”‚                                                                 â”‚\nâ”‚  1. Process is fully defined and unchanging                    â”‚\nâ”‚     â†’ Use: Simple automation/RPA                               â”‚\nâ”‚                                                                 â”‚\nâ”‚  2. Single-turn question answering                             â”‚\nâ”‚     â†’ Use: RAG or chatbot                                      â”‚\nâ”‚                                                                 â”‚\nâ”‚  3. Safety requires complete human control                     â”‚\nâ”‚     â†’ Use: Human-in-the-loop system                            â”‚\nâ”‚                                                                 â”‚\nâ”‚  4. Task is simple lookup or calculation                       â”‚\nâ”‚     â†’ Use: Traditional software                                â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Architecture Selection Guide\n\n| Your Scenario | Recommended Architecture | Why |\n|---------------|-------------------------|-----|\n| **Simple condition-action** (e.g., alert on threshold) | Simple Reflex | Fast, predictable, low complexity |\n| **Need to track state** (e.g., inventory management) | Model-Based | Handles partial observability |\n| **Complex goal achievement** (e.g., project planning) | Goal-Based or ReAct | Plans toward objectives |\n| **Trade-off decisions** (e.g., resource allocation) | Utility-Based | Optimizes across constraints |\n| **Improve over time** (e.g., customer preferences) | Learning Agent | Adapts to patterns |\n| **Research & analysis** (e.g., market research) | ReAct | Transparent reasoning + tools |\n| **Cross-functional workflow** (e.g., order-to-cash) | Multi-Agent | Distributed specialization |\n\n---\n\n### âœ… Self-Assessment Checklist\n\nBefore moving on to Week 7, ensure you can:\n\n**Core Concepts**\n- [ ] Define what makes a system \"agentic\" (autonomy, planning, reasoning, tool use)\n- [ ] Explain the perception-action loop in your own words\n- [ ] Distinguish between automation, chatbots, and agentic systems\n- [ ] Describe how memory supports agent behavior\n\n**Frameworks & Architectures**\n- [ ] Explain the ReAct framework (Reasoning + Acting)\n- [ ] Identify which architecture fits a given scenario\n- [ ] Trace through a perception-action cycle for a business task\n- [ ] List the 6 key characteristics of agentic systems\n\n**Real-World Application**\n- [ ] Identify a task in your organization that needs agentic capabilities\n- [ ] Explain WHY simple automation wouldn't work for that task\n- [ ] Design a basic agent architecture for a business problem\n- [ ] Articulate the value proposition of agentic AI to stakeholders\n\n**Strategic Thinking**\n- [ ] Evaluate trade-offs between autonomy and human oversight\n- [ ] Assess risks of deploying agentic systems\n- [ ] Determine appropriate safeguards and failure modes\n- [ ] Justify ROI for an agentic solution vs. alternatives\n\n---\n\n### ğŸ¯ Mastery Indicators\n\n**Foundational Understanding**\n- You can draw the perception-action loop from memory\n- You can explain Klarna's agent in terms of the 6 characteristics\n- You can spot the difference between agentic and non-agentic in examples\n\n**Applied Skills**\n- You've designed an agent for a real task from your work\n- You've chosen an appropriate architecture and can justify why\n- You've identified required tools and capabilities\n\n**Strategic Insight**\n- You can advise when NOT to use agentic AI\n- You can estimate value creation from agentic capabilities\n- You can discuss autonomy levels and governance\n\n---\n\n### ğŸ“ If you checked all boxes:\nExcellent! You have a solid grasp of agentic fundamentals and are ready to explore multi-agent systems in Week 7.\n\n### ğŸ¤” If you have gaps:\nFocus your review:\n- **Definitions**: Revisit Section 1 (What is Agentic?)\n- **Comparison**: Review Section 2 (Agents vs. Automation vs. Chatbots)\n- **Concepts**: Study Sections 3-4 (Perception, Planning, Reasoning, Memory)\n- **ReAct**: Work through Section 5 (ReAct Framework examples)\n- **Real-World**: Read the case studies and map to concepts\n\n---\n\n### ğŸ’¡ Pro Tips for Week 7 Preparation\n\n1. **Think Multi-Agent**: Identify a complex process involving multiple roles/departments\n2. **Communication Patterns**: Notice how teams coordinate - agents will too\n3. **Specialization**: Consider which tasks need specialized vs. general agents\n4. **Handoffs**: Think about when one agent should pass work to another",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "1. **Agentic systems combine autonomy, planning, reasoning, and tool use** to handle complex tasks that require adaptive behavior\n",
    "\n",
    "2. **Agents differ fundamentally from automation and chatbots** through their ability to plan, reason dynamically, and operate with meaningful autonomy\n",
    "\n",
    "3. **The perception-action loop is fundamental** to agent behavior: perceive â†’ reason â†’ plan â†’ act â†’ observe â†’ repeat\n",
    "\n",
    "4. **ReAct framework interleaves reasoning and acting**, enabling more transparent and effective problem-solving\n",
    "\n",
    "5. **Different architectures serve different purposes** - choose based on task complexity, observability, and learning requirements\n",
    "\n",
    "6. **Business value comes from handling complex, multi-step tasks** that are difficult to pre-program or script\n",
    "\n",
    "7. **Careful consideration of autonomy, safeguards, and oversight** is essential for business deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Looking Ahead to Week 7\n",
    "\n",
    "Next week, we'll explore **Agentic Frameworks: Multi-Agent Systems & Collaboration**.\n",
    "\n",
    "We'll cover:\n",
    "- Multi-Agent Systems (MAS) concepts\n",
    "- Communication protocols between agents\n",
    "- Coordination and collaboration strategies\n",
    "- Applications in complex business scenarios\n",
    "\n",
    "**Preparation:** Think about business processes that involve multiple roles or departments coordinating together. How might multiple specialized agents work together on such tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Frameworks and Tools:\n",
    "- [LangChain Agents](https://python.langchain.com/docs/modules/agents/) - Agent implementation framework\n",
    "- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) - Autonomous agent example\n",
    "- [BabyAGI](https://github.com/yoheinakajima/babyagi) - Task-driven autonomous agent\n",
    "\n",
    "### Academic Resources:\n",
    "- [ReAct Paper (Yao et al., 2022)](https://arxiv.org/abs/2210.03629)\n",
    "- [LLM Agents Survey (Xi et al., 2023)](https://arxiv.org/abs/2309.07864)\n",
    "- [Generative Agents (Park et al., 2023)](https://arxiv.org/abs/2304.03442)\n",
    "\n",
    "### Practical Guides:\n",
    "- [Building LLM Agents - Anthropic](https://docs.anthropic.com/claude/docs/)\n",
    "- [Agent Patterns - OpenAI](https://platform.openai.com/docs/guides/agents)\n",
    "\n",
    "---\n",
    "\n",
    "*End of Week 6 Notebook*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}