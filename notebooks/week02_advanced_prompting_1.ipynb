{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Advanced Prompting I - Few-Shot, Chain-of-Thought & Self-Ask\n",
    "\n",
    "## MBA 590 - Advanced AI Strategy: Prompting and Agentic Frameworks\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This week advances beyond basic prompting to explore sophisticated techniques that significantly improve LLM performance on complex tasks. We'll master few-shot learning for improved context, implement Chain-of-Thought (CoT) prompting for complex reasoning, and explore Self-Ask for breaking down problems.\n",
    "\n",
    "### Key Topics\n",
    "- Few-shot learning and in-context learning\n",
    "- Chain-of-Thought (CoT) prompting\n",
    "- Self-Ask prompting technique\n",
    "- When and how to apply each technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this week, you will be able to:\n",
    "\n",
    "1. Apply few-shot learning techniques to provide examples for better context\n",
    "2. Implement Chain-of-Thought prompting to elicit step-by-step reasoning\n",
    "3. Use Self-Ask techniques to decompose complex questions\n",
    "4. Evaluate when each advanced technique is most appropriate\n",
    "5. Combine multiple techniques for optimal results\n",
    "6. Analyze complex decision-making scenarios using CoT prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Academic Readings\n",
    "\n",
    "1. **Wei, J., Wang, X., Schuurmans, D., et al. (2022).** *Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.* arXiv preprint arXiv:2201.11903.\n",
    "\n",
    "2. **Press, O., Zhang, M., Min, S., et al. (2022).** *Measuring and Narrowing the Compositionality Gap in Language Models.* arXiv preprint arXiv:2210.03350."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Few-Shot Learning\n",
    "\n",
    "### What is Few-Shot Learning?\n",
    "\n",
    "Few-shot learning involves providing the LLM with a small number of examples (typically 1-5) to demonstrate the desired output format, style, or reasoning pattern.\n",
    "\n",
    "### Types:\n",
    "- **Zero-shot**: No examples (covered in Week 1)\n",
    "- **One-shot**: One example\n",
    "- **Few-shot**: Multiple examples (typically 2-5)\n",
    "\n",
    "### Benefits:\n",
    "- Improved output consistency\n",
    "- Better format compliance\n",
    "- Enhanced understanding of complex tasks\n",
    "- Reduced ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Sentiment Analysis of Customer Reviews\n",
    "\n",
    "# Zero-shot approach (from Week 1)\n",
    "zero_shot = \"\"\"\n",
    "Analyze the sentiment of this customer review:\n",
    "\"The product arrived quickly but the quality was disappointing.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"ZERO-SHOT PROMPT:\")\n",
    "print(zero_shot)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot approach\n",
    "few_shot = \"\"\"\n",
    "Analyze the sentiment of customer reviews and categorize them as Positive, Negative, or Mixed.\n",
    "Provide a brief explanation.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Review: \"This product exceeded my expectations! Great value for money.\"\n",
    "Sentiment: Positive\n",
    "Explanation: Customer expresses satisfaction and highlights value, indicating a positive experience.\n",
    "\n",
    "Review: \"Terrible experience. Product broke after one week.\"\n",
    "Sentiment: Negative\n",
    "Explanation: Customer reports product failure and explicitly states dissatisfaction.\n",
    "\n",
    "Review: \"Good features but overpriced for what you get.\"\n",
    "Sentiment: Mixed\n",
    "Explanation: Customer acknowledges positive aspects (features) but has concerns about value.\n",
    "\n",
    "Now analyze this review:\n",
    "Review: \"The product arrived quickly but the quality was disappointing.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"FEW-SHOT PROMPT:\")\n",
    "print(few_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-Shot Best Practices\n",
    "\n",
    "1. **Choose diverse examples** that cover different scenarios\n",
    "2. **Maintain consistent format** across all examples\n",
    "3. **Quality over quantity** - 2-3 good examples often outperform 5+ mediocre ones\n",
    "4. **Match the task complexity** in your examples\n",
    "5. **Include edge cases** when relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Business Email Classification\n",
    "\n",
    "few_shot_email = \"\"\"\n",
    "Classify business emails into categories: URGENT, ROUTINE, or INFORMATIONAL.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Email: \"Server outage affecting all customers. Need immediate response.\"\n",
    "Category: URGENT\n",
    "Reason: Critical system issue requiring immediate attention.\n",
    "\n",
    "Email: \"Please submit your weekly report by Friday.\"\n",
    "Category: ROUTINE\n",
    "Reason: Standard operational request with clear deadline.\n",
    "\n",
    "Email: \"FYI: Office will close early next Monday for maintenance.\"\n",
    "Category: INFORMATIONAL\n",
    "Reason: Advance notice of scheduled event, no action required.\n",
    "\n",
    "Now classify this email:\n",
    "Email: \"Budget approval needed for Q2 marketing campaign by EOD.\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"FEW-SHOT EMAIL CLASSIFICATION:\")\n",
    "print(few_shot_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "### What is Chain-of-Thought?\n",
    "\n",
    "Chain-of-Thought prompting encourages the LLM to break down complex problems into intermediate reasoning steps, similar to how humans approach problem-solving.\n",
    "\n",
    "### Key Characteristics:\n",
    "- Explicit reasoning steps\n",
    "- Intermediate conclusions\n",
    "- Transparent decision-making process\n",
    "- Improved accuracy on complex tasks\n",
    "\n",
    "### When to Use CoT:\n",
    "- Multi-step problems\n",
    "- Mathematical calculations\n",
    "- Logical reasoning tasks\n",
    "- Complex decision-making\n",
    "- Tasks requiring verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Without Chain-of-Thought\n",
    "\n",
    "without_cot = \"\"\"\n",
    "A company had 450 customers in January. In February, they gained 120 new customers \n",
    "but lost 45 existing customers. In March, they gained 90 new customers and lost 30. \n",
    "What was the net change in customers from January to the end of March?\n",
    "\"\"\"\n",
    "\n",
    "print(\"WITHOUT CHAIN-OF-THOUGHT:\")\n",
    "print(without_cot)\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: With Chain-of-Thought\n",
    "\n",
    "with_cot = \"\"\"\n",
    "A company had 450 customers in January. In February, they gained 120 new customers \n",
    "but lost 45 existing customers. In March, they gained 90 new customers and lost 30. \n",
    "What was the net change in customers from January to the end of March?\n",
    "\n",
    "Let's solve this step by step:\n",
    "\"\"\"\n",
    "\n",
    "print(\"WITH CHAIN-OF-THOUGHT:\")\n",
    "print(with_cot)\n",
    "print(\"\\nExpected reasoning:\")\n",
    "print(\"Step 1: Calculate February change: +120 - 45 = +75\")\n",
    "print(\"Step 2: Calculate March change: +90 - 30 = +60\")\n",
    "print(\"Step 3: Calculate total change: +75 + 60 = +135\")\n",
    "print(\"Step 4: Verify: 450 + 135 = 585 total customers\")\n",
    "print(\"Answer: Net change of +135 customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain-of-Thought with Few-Shot Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Few-Shot + CoT for Business Decisions\n",
    "\n",
    "cot_few_shot = \"\"\"\n",
    "Analyze business scenarios and make a recommendation. Show your reasoning step by step.\n",
    "\n",
    "Example:\n",
    "Scenario: A SaaS company has 1000 customers paying $50/month. They're considering \n",
    "raising prices to $60/month but research suggests 15% of customers may cancel.\n",
    "\n",
    "Analysis:\n",
    "Step 1: Calculate current monthly revenue\n",
    "  - 1000 customers × $50 = $50,000/month\n",
    "\n",
    "Step 2: Calculate expected customer loss\n",
    "  - 15% of 1000 = 150 customers will cancel\n",
    "  - Remaining customers: 1000 - 150 = 850\n",
    "\n",
    "Step 3: Calculate new monthly revenue\n",
    "  - 850 customers × $60 = $51,000/month\n",
    "\n",
    "Step 4: Compare outcomes\n",
    "  - Revenue change: $51,000 - $50,000 = +$1,000/month\n",
    "  - Customer base: -15% (concerning for growth)\n",
    "\n",
    "Recommendation: Proceed with caution. While revenue increases slightly, losing 15% \n",
    "of customers could impact long-term growth and word-of-mouth. Consider:\n",
    "  - Testing with a smaller segment first\n",
    "  - Adding features to justify the increase\n",
    "  - Grandfathering existing customers at current rate\n",
    "\n",
    "Now analyze this scenario:\n",
    "Scenario: An e-commerce company spends $10,000/month on ads generating 500 customers \n",
    "with an average order value of $80 and a 25% repeat purchase rate within 3 months. \n",
    "They're considering increasing ad spend to $15,000/month, which should generate 700 \n",
    "customers. Should they increase the spend?\n",
    "\"\"\"\n",
    "\n",
    "print(\"CHAIN-OF-THOUGHT + FEW-SHOT PROMPT:\")\n",
    "print(cot_few_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Self-Ask Prompting\n",
    "\n",
    "### What is Self-Ask?\n",
    "\n",
    "Self-Ask is a technique where the LLM breaks down a complex question into sub-questions, answers each sub-question, and then synthesizes a final answer.\n",
    "\n",
    "### Structure:\n",
    "1. Initial complex question\n",
    "2. Generate relevant sub-questions\n",
    "3. Answer each sub-question\n",
    "4. Synthesize final answer\n",
    "\n",
    "### Benefits:\n",
    "- Better handling of multi-faceted questions\n",
    "- More comprehensive answers\n",
    "- Identifies gaps in information\n",
    "- Transparent reasoning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Ask Example\n",
    "\n",
    "self_ask_prompt = \"\"\"\n",
    "Question: Should our company invest in developing an AI chatbot for customer service?\n",
    "\n",
    "Let's break this down into sub-questions:\n",
    "\n",
    "Sub-question 1: What are our current customer service costs and pain points?\n",
    "Sub-question 2: What capabilities would an AI chatbot provide?\n",
    "Sub-question 3: What is the estimated cost of development and maintenance?\n",
    "Sub-question 4: What percentage of customer queries could a chatbot handle?\n",
    "Sub-question 5: What are the risks and potential downsides?\n",
    "Sub-question 6: How does this align with our strategic priorities?\n",
    "\n",
    "Now, let's answer each sub-question and reach a conclusion.\n",
    "\"\"\"\n",
    "\n",
    "print(\"SELF-ASK PROMPT:\")\n",
    "print(self_ask_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Ask Template\n",
    "\n",
    "Here's a reusable template for Self-Ask prompting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_self_ask_prompt(main_question: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a Self-Ask prompt template for complex questions.\n",
    "    \n",
    "    Args:\n",
    "        main_question: The complex question to analyze\n",
    "    \n",
    "    Returns:\n",
    "        A formatted Self-Ask prompt\n",
    "    \"\"\"\n",
    "    template = f\"\"\"\n",
    "Main Question: {main_question}\n",
    "\n",
    "To answer this comprehensively, let's break it down into sub-questions:\n",
    "\n",
    "Step 1: Identify the key sub-questions that need to be answered.\n",
    "Step 2: Answer each sub-question with relevant information.\n",
    "Step 3: Synthesize the answers into a comprehensive response.\n",
    "Step 4: Provide a clear recommendation or conclusion.\n",
    "\n",
    "Let's begin:\n",
    "\"\"\"\n",
    "    return template\n",
    "\n",
    "# Example usage\n",
    "question = \"Should we expand our business into the European market?\"\n",
    "prompt = create_self_ask_prompt(question)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparative Analysis: When to Use Each Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "technique_comparison = {\n",
    "    'Technique': ['Zero-Shot', 'Few-Shot', 'Chain-of-Thought', 'Self-Ask'],\n",
    "    'Best For': [\n",
    "        'Simple, common tasks',\n",
    "        'Format consistency, style matching',\n",
    "        'Complex reasoning, calculations',\n",
    "        'Multi-faceted questions'\n",
    "    ],\n",
    "    'Complexity': ['Low', 'Medium', 'High', 'High'],\n",
    "    'Token Cost': ['Low', 'Medium', 'Medium-High', 'High'],\n",
    "    'Output Quality': ['Variable', 'Consistent', 'High for reasoning', 'Comprehensive'],\n",
    "    'Setup Time': ['Minimal', 'Low-Medium', 'Low', 'Low-Medium']\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(technique_comparison)\n",
    "print(\"Prompting Technique Comparison\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Practical Exercise: Complex Decision Analysis\n",
    "\n",
    "### Scenario:\n",
    "You're a business leader deciding whether to implement a new technology initiative. Apply Chain-of-Thought prompting to analyze the decision.\n",
    "\n",
    "**Business Context:**\n",
    "- Your retail company has 50 physical stores\n",
    "- Annual revenue: $100M\n",
    "- Current IT budget: $5M/year\n",
    "- Considering: Implementing AI-powered inventory management\n",
    "- Estimated cost: $2M implementation + $500K/year maintenance\n",
    "- Projected savings: 20% reduction in inventory costs (currently $30M/year)\n",
    "- Projected risks: 6-month implementation, potential staff resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chain-of-Thought analysis\n",
    "\n",
    "cot_decision_prompt = \"\"\"\n",
    "Decision: Should we implement AI-powered inventory management?\n",
    "\n",
    "Let's analyze this step by step:\n",
    "\n",
    "Step 1: Calculate financial impact\n",
    "  Current inventory costs: $30M/year\n",
    "  Projected savings (20%): $30M × 0.20 = $6M/year\n",
    "  Implementation cost: $2M (one-time)\n",
    "  Annual maintenance: $500K/year\n",
    "  \n",
    "  Year 1 net: $6M - $2M - $500K = $3.5M savings\n",
    "  Year 2+ net: $6M - $500K = $5.5M/year savings\n",
    "  \n",
    "  ROI calculation:\n",
    "  - Payback period: $2M / $5.5M ≈ 4.4 months (after year 1)\n",
    "  - 3-year total savings: $3.5M + $5.5M + $5.5M = $14.5M\n",
    "\n",
    "Step 2: Assess budget impact\n",
    "  Current IT budget: $5M/year\n",
    "  Year 1 total needed: $2M + $500K = $2.5M (50% of annual budget)\n",
    "  Ongoing cost: $500K (10% of annual budget)\n",
    "  Conclusion: Significant but manageable within current budget\n",
    "\n",
    "Step 3: Evaluate risks\n",
    "  - 6-month implementation: Moderate disruption risk\n",
    "  - Staff resistance: Requires change management\n",
    "  - Technology risk: Proven technology, lower risk\n",
    "  - Competitive risk: Competitors may already be implementing similar solutions\n",
    "\n",
    "Step 4: Consider strategic alignment\n",
    "  Benefits:\n",
    "  - Improves operational efficiency\n",
    "  - Reduces stockouts and overstock\n",
    "  - Provides data for better decision-making\n",
    "  - Modernizes technology stack\n",
    "  \n",
    "  Challenges:\n",
    "  - Requires staff training\n",
    "  - Temporary productivity impact during transition\n",
    "  - Need for change management program\n",
    "\n",
    "Step 5: Final recommendation\n",
    "  Strong financial case: $14.5M savings over 3 years, 4.4-month payback\n",
    "  Manageable risks with proper planning\n",
    "  Strategic alignment with operational excellence goals\n",
    "  \n",
    "  RECOMMENDATION: PROCEED with implementation\n",
    "  \n",
    "  Key success factors:\n",
    "  1. Develop comprehensive change management plan\n",
    "  2. Pilot with 5-10 stores before full rollout\n",
    "  3. Invest in staff training (budget $200K)\n",
    "  4. Establish clear KPIs and monitoring\n",
    "  5. Plan for 6-month transition period\n",
    "\"\"\"\n",
    "\n",
    "print(\"CHAIN-OF-THOUGHT DECISION ANALYSIS:\")\n",
    "print(cot_decision_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Your Turn: Apply Advanced Prompting Techniques\n",
    "\n",
    "### Exercise 1: Few-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few-shot prompt for a business task of your choice\n",
    "\n",
    "your_few_shot = \"\"\"\n",
    "[Create your few-shot prompt here]\n",
    "\n",
    "Task: [Describe your task]\n",
    "\n",
    "Example 1:\n",
    "[Your first example]\n",
    "\n",
    "Example 2:\n",
    "[Your second example]\n",
    "\n",
    "Example 3 (optional):\n",
    "[Your third example]\n",
    "\n",
    "Now apply to:\n",
    "[Your target case]\n",
    "\"\"\"\n",
    "\n",
    "print(your_few_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Chain-of-Thought for Your Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chain-of-Thought prompt for a complex decision in your field\n",
    "\n",
    "your_cot_scenario = \"\"\"\n",
    "[Describe your complex decision scenario]\n",
    "\"\"\"\n",
    "\n",
    "your_cot_prompt = \"\"\"\n",
    "Decision: [Your decision question]\n",
    "\n",
    "Let's analyze this step by step:\n",
    "\n",
    "Step 1: [First aspect to analyze]\n",
    "\n",
    "Step 2: [Second aspect to analyze]\n",
    "\n",
    "Step 3: [Third aspect to analyze]\n",
    "\n",
    "Step 4: [Synthesize and conclude]\n",
    "\"\"\"\n",
    "\n",
    "print(\"Your Scenario:\")\n",
    "print(your_cot_scenario)\n",
    "print(\"\\nYour Chain-of-Thought Prompt:\")\n",
    "print(your_cot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Self-Ask Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Self-Ask prompt for a multi-faceted business question\n",
    "\n",
    "your_complex_question = \"\"\"\n",
    "[Write your complex business question here]\n",
    "\"\"\"\n",
    "\n",
    "your_self_ask = create_self_ask_prompt(your_complex_question)\n",
    "print(your_self_ask)\n",
    "\n",
    "# Now list the sub-questions you would want the LLM to address:\n",
    "sub_questions = \"\"\"\n",
    "Sub-question 1: [Your first sub-question]\n",
    "Sub-question 2: [Your second sub-question]\n",
    "Sub-question 3: [Your third sub-question]\n",
    "Sub-question 4: [Your fourth sub-question]\n",
    "[Add more as needed]\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nSub-questions to explore:\")\n",
    "print(sub_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Discussion Activity\n",
    "\n",
    "### Main Prompt:\n",
    "\n",
    "**Identify a complex decision-making scenario in your field. How could Chain-of-Thought prompting help an LLM analyze the factors involved more effectively than a simple prompt? Outline the potential steps in the chain.**\n",
    "\n",
    "Use the cell below to document your analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Analysis:\n",
    "\n",
    "**My Decision Scenario:**\n",
    "\n",
    "[Describe your complex decision scenario]\n",
    "\n",
    "**Why Chain-of-Thought is Better Than Simple Prompting:**\n",
    "\n",
    "[Explain the advantages]\n",
    "\n",
    "**Proposed Chain-of-Thought Steps:**\n",
    "\n",
    "1. [First step in reasoning]\n",
    "2. [Second step]\n",
    "3. [Third step]\n",
    "4. [Fourth step]\n",
    "5. [Final synthesis]\n",
    "\n",
    "**Expected Benefits:**\n",
    "\n",
    "[What improvements do you expect in the output?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Combinations\n",
    "\n",
    "The most powerful prompts often combine multiple techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Few-Shot + Chain-of-Thought + Self-Ask\n",
    "\n",
    "combined_advanced = \"\"\"\n",
    "Task: Evaluate market entry decisions using structured analysis.\n",
    "\n",
    "Example Analysis:\n",
    "Question: Should Company A enter the Indian market?\n",
    "\n",
    "Sub-questions to address:\n",
    "1. What is the market size and growth rate?\n",
    "2. Who are the main competitors?\n",
    "3. What are regulatory requirements?\n",
    "4. What are cost implications?\n",
    "5. What are strategic fit considerations?\n",
    "\n",
    "Step-by-step analysis:\n",
    "Step 1: Market opportunity\n",
    "  - Market size: $500M, growing at 15% annually\n",
    "  - Target segment: 50M potential customers\n",
    "  - Analysis: Strong growth market with significant opportunity\n",
    "\n",
    "Step 2: Competitive landscape\n",
    "  - 3 major competitors with 60% market share\n",
    "  - Multiple small players with 40%\n",
    "  - Analysis: Competitive but fragmented market allows for entry\n",
    "\n",
    "Step 3: Regulatory environment\n",
    "  - Foreign investment allowed with local partner (51% local ownership)\n",
    "  - 18% tax rate on revenues\n",
    "  - Analysis: Manageable regulations with right partner\n",
    "\n",
    "Step 4: Financial implications\n",
    "  - Entry cost: $5M\n",
    "  - Break-even: Year 2\n",
    "  - Projected revenue Year 3: $15M\n",
    "  - Analysis: Acceptable investment with reasonable payback\n",
    "\n",
    "Step 5: Strategic alignment\n",
    "  - Aligns with global expansion strategy\n",
    "  - Diversifies revenue sources\n",
    "  - Builds emerging market expertise\n",
    "  - Analysis: Strong strategic fit\n",
    "\n",
    "Conclusion: RECOMMEND entry with local partner\n",
    "Key success factors: Partner selection, regulatory compliance, market adaptation\n",
    "\n",
    "---\n",
    "\n",
    "Now analyze:\n",
    "Question: Should Company B acquire a smaller competitor for $50M?\n",
    "\n",
    "Company B details:\n",
    "- Annual revenue: $200M\n",
    "- Cash reserves: $80M\n",
    "- Debt: $30M\n",
    "\n",
    "Target company details:\n",
    "- Annual revenue: $25M\n",
    "- EBITDA: $5M\n",
    "- Market share in key segment: 15%\n",
    "- Complementary technology: Yes\n",
    "- Culture fit: Unknown\n",
    "\"\"\"\n",
    "\n",
    "print(\"COMBINED ADVANCED PROMPTING:\")\n",
    "print(combined_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "1. **Few-shot learning** provides context through examples, improving output consistency and format compliance\n",
    "\n",
    "2. **Chain-of-Thought** breaks down complex reasoning into steps, dramatically improving accuracy on complex tasks\n",
    "\n",
    "3. **Self-Ask** decomposes complex questions into manageable sub-questions for comprehensive analysis\n",
    "\n",
    "4. **Combining techniques** often yields the best results for complex business scenarios\n",
    "\n",
    "5. **Technique selection** should be based on:\n",
    "   - Task complexity\n",
    "   - Need for transparency\n",
    "   - Token budget\n",
    "   - Output requirements\n",
    "\n",
    "6. **Iteration and testing** remain essential - these techniques improve but don't guarantee perfect outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Looking Ahead to Week 3\n",
    "\n",
    "Next week, we'll explore:\n",
    "- Problem decomposition techniques (Least-to-Most prompting)\n",
    "- Self-correction methods (Self-Refine)\n",
    "- Chain-of-Verification for reducing errors\n",
    "- Iterative refinement strategies\n",
    "\n",
    "**Preparation:** Think about a task where an LLM might make errors that need correction or refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "### Research Papers:\n",
    "- [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)\n",
    "- [Self-Ask Prompting](https://arxiv.org/abs/2210.03350)\n",
    "- [Few-Shot Learning with LLMs](https://arxiv.org/abs/2005.14165)\n",
    "\n",
    "### Tools:\n",
    "- [OpenAI Playground](https://platform.openai.com/playground) - Test different prompting techniques\n",
    "- [Anthropic Console](https://console.anthropic.com/) - Experiment with Claude\n",
    "\n",
    "---\n",
    "\n",
    "*End of Week 2 Notebook*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
